[{"content":"Exploring TLS Automation — A Proof of Concept with n8n and Vault Managing TLS certificates often means chasing expiry dates, setting reminders, and manually rotating certs—a process that’s fragile and prone to outages. To prove there’s a better way, I built a prototype combining n8n and HashiCorp Vault that demonstrates the power of automation, and had the opportunity to present this work as a talk at Mumbai FOSS 2025. The Prototype in Action\nThe workflow I showcased was simple yet powerful:\nMonitoring expiry with early alerts\nTriggering automatic renewals via Vault’s PKI engine\nDeploying renewed certificates without manual steps\nValidating results in Vault for full transparency\nThis wasn’t a slide deck—it was about demonstrating the ability such a system can provide: hands-off certificate lifecycle management, built entirely on open-source tools.\nWhy n8n + Vault?\nn8n brings the flexibility of a visual automation platform—easy to extend, no coding required for most steps.\nVault provides a battle-tested PKI engine with strong security guarantees.\nTogether, they eliminate vendor lock-in, subscription costs, and opaque “black box” processes.\nBeyond the Demo\nWhile I shared this prototype in a lightning talk at Mumbai FOSS 2025, the real takeaway is that any team can replicate it today. Whether managing a handful of certs or rolling this out across multiple environments, the approach scales with your needs.\nAs a bonus, this same session was also wait-listed for the Open Source Summit India 2025, highlighting the growing interest in practical, open-source security automation.\n","permalink":"https://codeklutz.com/posts/exploring-tls-automation-a-proof-of-concept-with-n8n-and-vault/","summary":"Exploring TLS Automation — A Proof of Concept with n8n and Vault Managing TLS certificates often means chasing expiry dates, setting reminders, and manually rotating certs—a process that’s fragile and prone to outages. To prove there’s a better way, I built a prototype combining n8n and HashiCorp Vault that demonstrates the power of automation, and had the opportunity to present this work as a talk at Mumbai FOSS 2025. The Prototype in Action","title":" Exploring TLS Automation — A Proof of Concept with n8n and Vault"},{"content":"My First Tech Talk: The Journey from Panic to Presentation I recently had an opportunity to give a technical talk at GitTogether Mumbai. This is a small blog post based on my experience of giving a talk and a little behind-the-scenes turmoil written as a blog post.\nHow Do You Secure a Speaking Slot? This was the big question! It took me countless applications, several rejections, and a sprinkle of luck. The trick? Pitch a talk that fits what the audience and organizers are looking for—it\u0026rsquo;s all about relevance.\nWhat happens after my talk was selected? The talk has been selected \u0026hellip;\u0026hellip;so now what? The Panic strikes through!! But so does the cycle of preparation\u0026hellip;\u0026hellip;\nWill They Find It Interesting? Creating a talk is one thing, delivering it in a way that keeps the audience engaged is another. Once the panic and excitement strikes through so does the preparation. Preparing the contents for a talk is very different from presenting it. The information you INTEND to convey has to reach the audience in a way they perceive it and it has to be relatable and interesting for them to continue to listen!\nFeedback Feedback Feedback and Continuous Feedback! Ah yes, feedback—every speaker’s best friend (and occasional frenemy). It’s the secret sauce to leveling up your presentation, and trust me, you’ll need lots of it! I took every nugget of constructive criticism and tweaked my talk like a codebase on release day.\nNow, let’s talk demos. The ultimate double-edged sword. Engineers love them but for presenters? A living nightmare! And guess what? I willingly walked into that nightmare. Yep, I gave a demo!\nWhy? Well, demos are like live-action thrillers—great for the audience but full of nerve-wracking moments for the speaker. Something is bound to go wrong (and spoiler: it did). Cue the sweaty palms and heart palpitations as things start to go wrong! But hey, the key is to stay calm, crack a joke or two, and power through the glitches.\nIn hindsight, the demo could’ve been smoother, but for my first big talk, it wasn’t a complete disaster. Want to witness the chaos? Here’s the link to the demo fail Link I’m open to feedback (and maybe a little sympathy)!\nFinal Thoughts Every developer should experience the thrill of presenting their work to an appreciative public audience. It\u0026rsquo;s more than just sharing your knowledge—it’s a chance to push your limits, boost your confidence, and ignite a deeper passion for learning. Stepping onto that stage changes the way you see yourself as a developer, fueling your drive to grow and evolve. Plus, there’s nothing quite like the energy of connecting with others and realizing how far you’ve come on your journey!\nDo checkout my presentation link and feel free to provide any feedback via email or on Linkedin!\n","permalink":"https://codeklutz.com/posts/my-first-tech-talk-the-journey-from-panic-to-presentation/","summary":"My First Tech Talk: The Journey from Panic to Presentation I recently had an opportunity to give a technical talk at GitTogether Mumbai. This is a small blog post based on my experience of giving a talk and a little behind-the-scenes turmoil written as a blog post.\nHow Do You Secure a Speaking Slot? This was the big question! It took me countless applications, several rejections, and a sprinkle of luck.","title":" My First Tech Talk: The Journey from Panic to Presentation"},{"content":"I decided to write a blog after a long time of pondering and no ideas to write anything interesting about. So I just decided to write about leetcode today which Im doing. Some mini tricks I learnt by doing the problem https://leetcode.com/problems/kth-largest-element-in-a-stream/description/ When the problem asks for kth smallest or kth largest, typically it is supposed to be solved using Heap. And for Kth largest element the opposite element (which is smallest in this case is on top). Typically when one says Heap, we usually remember the tree diagram on google. However when in it comes to solving DS leetcode style problem I found out just using a Priority queue is simply enough. In Priority Queue, you just add the elements and it gives them a priority and sorts it .\nIn short,\nKth largest --\u0026gt; Min heap --\u0026gt; where smallest element is at top --\u0026gt; Uses Priority queue Kth smallest --\u0026gt; Max heap --\u0026gt; where the Largest element is at top --\u0026gt; Uses Priority queue in reverse Order Also Priority Queue\nadd : when an element cannot be added in queue it throws an exception offer : when an element cannot be added in queue it returns false ","permalink":"https://codeklutz.com/posts/today-i-learnt-til-leetcode-mini-bite-heap-and-priority-queue/","summary":"I decided to write a blog after a long time of pondering and no ideas to write anything interesting about. So I just decided to write about leetcode today which Im doing. Some mini tricks I learnt by doing the problem https://leetcode.com/problems/kth-largest-element-in-a-stream/description/ When the problem asks for kth smallest or kth largest, typically it is supposed to be solved using Heap. And for Kth largest element the opposite element (which is smallest in this case is on top).","title":"Today I learnt (TIL): Leetcode Mini Bite Heap and Priority Queue "},{"content":"Recently my friend gave me a Thkinking Fast and Slow Concepts book by Daniel Kahneman. I related to a lot of his. concepts and how it apply to my daily programming life a lot!\nThe book involves recognizing and managing cognitive biases while leveraging both intuitive and analytical thinking.the book explains 2 systems System 1 (Fast Thinking): This is the intuitive and automatic mode of thinking. It operates quickly and without much effort, making snap judgments and assumptions. It’s driven by emotion and instinct.\nSystem 2 (Slow Thinking): This is the deliberate and analytical mode of thinking. It requires effort and is used in complex decision-making, requiring attention and logical thinking.\nAs a programmer, we need to use System 2 a lot but sometimes in certain deadline situations, we tend to use System 1 a lot. Throughout the book, Kahneman discusses how these two systems influence our decisions and lead to various cognitive biases. Some key concepts include:\nHeuristics: Mental shortcuts that ease the cognitive load of making decisions. Prospect Theory: People value gains and losses differently, leading to irrational decision-making. The Anchoring Effect: Relying too heavily on the first piece of information seen (the \u0026ldquo;anchor\u0026rdquo;) when making decisions. Overconfidence Bias: The tendency to overestimate one’s abilities. Framing Effect: Decisions are influenced by the way information is presented.\nHere are some of the strategies that I thought were pretty useful from the book and could apply in my daily work.\nCode Reviews: Engage in regular code reviews with peers. This practice encourages System 2 thinking by requiring you to explain and justify your coding decisions. It also helps identify biases or errors that might have been overlooked by the original coder.\nPair Programming: This technique involves two programmers working together at one workstation/huddle. One writes the code while the other reviews each line as it is typed. The reviewer (navigator) uses System 2 thinking, providing immediate feedback and suggestions, while the driver can engage more in System 1, especially in familiar areas of coding.\nTest-Driven Development (TDD): TDD requires you to write tests before you write the actual code. This approach forces you to slow down and think about what you want to achieve (System 2) before getting involved in the coding itself (System 1).\nRefactoring with a Purpose: Systematically refactor code to improve its structure and readability without changing its functionality. This requires careful, analytical thinking to ensure that improvements are actual improvements and not just changes based on personal bias or preference.\nUsing Linters and Static Analysis Tools: Tools that analyze your code for errors, potential bugs, or style issues can help counteract the overconfidence bias by providing a \u0026ldquo;second opinion\u0026rdquo; that challenges your assumptions about your own code\u0026rsquo;s correctness.\nHeuristic Checklists: Develop or use existing checklists for code quality, security standards, and performance optimizations. This approach leverages structured thinking to ensure that common pitfalls and best practices are systematically considered.\nMindful Debugging: When debugging, it\u0026rsquo;s easy to quickly form a hypothesis and get tunnel vision. To counteract this, consciously explore multiple hypotheses and systematically verify or dismiss each one, ensuring that your initial assumptions don\u0026rsquo;t blind you to other possibilities.\nDocumentation and Comments: Writing clear documentation and code comments encourages you to think through your design and implementation choices. This reflective practice can help clarify your thoughts and expose any weak points in your reasoning.Though it should not be overused as people tend to write complicated code and cover it with comments and documentation.\nRegular Training on Cognitive Biases: Conduct sessions to educate yourself and your team on different types of cognitive biases and how they can affect programming and decision-making. This awareness can help everyone be more mindful of their thinking patterns and decision-making processes.\nBreak Large Problems into Smaller Parts: When faced with a complex problem, break it down into smaller, manageable tasks. This strategy helps manage the cognitive load, allowing System 2 to engage more effectively without being overwhelmed.\n","permalink":"https://codeklutz.com/posts/using-thinking-fast-and-slow-concepts-on-programming/","summary":"Recently my friend gave me a Thkinking Fast and Slow Concepts book by Daniel Kahneman. I related to a lot of his. concepts and how it apply to my daily programming life a lot!\nThe book involves recognizing and managing cognitive biases while leveraging both intuitive and analytical thinking.the book explains 2 systems System 1 (Fast Thinking): This is the intuitive and automatic mode of thinking. It operates quickly and without much effort, making snap judgments and assumptions.","title":"Using Thinking Fast and Slow Concepts on Programming"},{"content":"Today I learnt a few kubectl commands which I used to for debugging a few issues in testing environment at work.\nTo check logs kubectl logs -f pod_name Useful when you need to check logs inside a pod.\nTo get the bin bash inside a pod kubectl --exec --stdin --tty podname --bin/bash This is useful command to check for certain versions or debugging which is done This command was helpful for determining Java versions inside the pod which was used in a particular environment. Anytime you want to run terminal commands such as java --version Or something similar to execute commands which need a bash shell.This is a good approach. Helps to know which dependencies a pod uses.\nScale up and downscale your pod kubectl scale deployment \u0026lt;application-name\u0026gt; --replicas=0 kubectl scale deployment \u0026lt;application-name\u0026gt; --replicas=1 If your company uses a UI to scale up application pods and that UI tests your patience then this is a quick fix(Not recommended in PROD).\nGet description of your pod. kubectl describe services This commands gives general information regarding image IDs. If your company uses Jenkins to make builds and then deploys them uses kubernetes,and if you need a way to verify if Jenkins deployed that particular build.This one helps as you can cross verify that information using attributes such as (sha)\n","permalink":"https://codeklutz.com/posts/today-i-learnt-kubectl-commands-for-debugging/","summary":"Today I learnt a few kubectl commands which I used to for debugging a few issues in testing environment at work.\nTo check logs kubectl logs -f pod_name Useful when you need to check logs inside a pod.\nTo get the bin bash inside a pod kubectl --exec --stdin --tty podname --bin/bash This is useful command to check for certain versions or debugging which is done This command was helpful for determining Java versions inside the pod which was used in a particular environment.","title":"Today I learnt : Kubectl commands for debugging"},{"content":"We have all experienced this often where we are stuck on an issue. We feel we have not earned the right to ask the doubt yet till we reach an imaginary threshold or baseline. The feeling of doing some research before reaching out to someone.\nThen time passes and so does the feeling of shame.The shame of not being able to solve the doubt on my own and yet feeling the hesitation to reach out to a senior.\nThe best resolution no matter how much hesitation or shame is to ASK NOW! It does two things:-\nFilters out your misunderstandings and gives you clarity. Always end up learning something new. Also if the point is in just the idea or analysis stage ,one can validate the effectiveness of an idea faster . How much important or effective an idea is as a solution to a problem or if there are better solutions. ","permalink":"https://codeklutz.com/posts/when-to-ask-for-help-as-a-software-engineer/","summary":"We have all experienced this often where we are stuck on an issue. We feel we have not earned the right to ask the doubt yet till we reach an imaginary threshold or baseline. The feeling of doing some research before reaching out to someone.\nThen time passes and so does the feeling of shame.The shame of not being able to solve the doubt on my own and yet feeling the hesitation to reach out to a senior.","title":"When to ask for help as a Software Engineer?"},{"content":"Recently got an opportunity to work on angular project.With no previous experience in angular, I had some catch up to do in terms of web development.So here is a small blog post.\nWhat is Angular ? Framework to build client side applications.\nWhy would you use Angular? Vanilla JQuery code gets harder to maintain,harder to test.\nAnd like all most of the frameworks Junction, Angular provides:\nAngular gave our applications clean structure. Includes lots of Reusable code Makes the application more testable Also easier to co-relate to learn from Java perspective because of 2 features Dependency Injection Typescript gives our plain JS applications some structure \u0026amp; enables static typing.\n3 Handles Server-side Rendering We don\u0026rsquo;t save the data in client. We save it in server. Example: Data is wiped clean when user creates form.\nFrontend Backend \u0026ndash;\u0026gt; Backend (Presentation logic) Data APIs Business\nLet\u0026rsquo;s get familiar with some terms in Angular first. Below is small comparison to co relate between Java and angular.\nWhat Java Angular Dependency management Maven npm(node package manager ) Build/package Maven webpack Library Repo Maven Central npmjs.org Project Descriptor pom.xml package.json Programming language Java Typescript ,HTML Platform runtime JVM Browser/NodeJS Unit Testing Junit Karma/jasmine Reactive Programming RxJava RxJS Code style checks Sonar eslint Browser End-to-end testing Webdriver Protractor (Layer on top of selenium) Like java has a main file. Similarly in angular, there is a main.ts file which is the starting point of our application.It is present in bootstrapmodule(Appmodule).\nWebpack Angular uses a tool called webpack which is a static module bundler.It takes all our HTML,CSS and JS files and bundles them into a single file which is loaded by the browser. It bundles application source code into convenient chunks, to improve performance and load times. Hot Module replacement Hot Module Replacement (HMR) is a feature of webpack that allows developers to update code changes without the need for a full page reload. When a code change is made, HMR only updates the module that has been modified, which means the application can continue running while the changes are applied.\n","permalink":"https://codeklutz.com/posts/learning-angular-as-a-java-developer/","summary":"Recently got an opportunity to work on angular project.With no previous experience in angular, I had some catch up to do in terms of web development.So here is a small blog post.\nWhat is Angular ? Framework to build client side applications.\nWhy would you use Angular? Vanilla JQuery code gets harder to maintain,harder to test.\nAnd like all most of the frameworks Junction, Angular provides:\nAngular gave our applications clean structure.","title":"Learning Angular as a Java Developer"},{"content":"While I migrating this website, I came across many issues. One such issue was git submodule.So here is a post on it.\nwhat is a git submodule? Git submodule is a way to include another repository in Git as a sub directory in one repository.\nIt allows you to keep another repo(your own repo or someone else) in your repo as a subdirectory It is useful for track that repo\u0026rsquo;s changes and use that project repo as a reference.\ngit submodule add https://github.com/username/repo-name.git It’s important to note the username of the repo you are adding. Because whose username is present in the repo, the repo belongs to them. So they have ownership of the repo and the changes over it.\nWhat issue I faced ? I use Hugo Papermod theme for this website. I used the git submodule method for installing this theme in my Hugo repo.\ngit submodule https://github.com/adityatelange/hugo-PaperMod.git --depth=1 Instead of\ngit submodule https://github.com/MY-GITHUB-USERNAME/hugo-PaperMod.git --depth=1 What did this lead to? For adding GitHub comments feature, the changes had to be done inside layout/partials/comments.html\nThis file is present in the submodule directory.This lead to the below error:\nwarning: adding embedded git repository: themes/PaperMod hint: You’ve added another git repository inside your current repository. hint: Clones of the outer repository will not contain the contents of hint: the embedded repository and will not know how to obtain it. hint: If you meant to add a submodule, use: hint: hint: git submodule add \u0026lt;url\u0026gt; themes/PaperMod hint: hint: If you added this path by mistake, you can remove it from the hint: index with: hint: hint: git rm --cached themes/PaperMod hint: hint: See “git help submodule” for more information. I couldn’t push my changes into repo since I did not have ownership over it\nHow to solve this? There were two ways to solve this:-\nI make a PR of my changes in aditya subdirectory. The owner approves my changes. This is not possible in this case since these changes are custom to my repo and not feature enhancement or bug fix\nI remove all git submodule of Aditya ’s changes .Fork Aditya papermod theme(so now the forked repo belong to me ) and link the git submodule to my forked repo. I went with the second route.\nBut turns out removing all references of git submodule can be quite annoying.\nEvery time I thought I removed all submodule references using stackoverflow answers I ended up on the same above error. This meant there were still submodule references present.\nFound this useful Github Gist\nDelete the relevant section from the .gitmodules file. Delete the relevant section from the .gitmodules file. In my case entries looked like\n│ [submodule “themes/PaperMod”] 2 │ path = themes/PaperMod 3 │ url = https://github.com/adityatelange/hugo-PaperMod.git Stage the .gitmodules changes git add .gitmodules\nDelete the relevant section from .git/config For me no submodule entries were present.\nRun git rm --cached path_to_submodule (no trailing slash).In my case it was git rm --cached themes/Papermod\nRun rm -rf .git/modules/path_to_submodule (no trailing slash).\nCommit git commit -m “Removed submodule ”\nDelete the now untracked submodule files rm -rf path_to_submodule\nThis removed my git submodules entries. And then again created a submodule entry with my usernameAnd that\u0026rsquo;s how the git submodule error was solved. **\n","permalink":"https://codeklutz.com/posts/today-i-learnt-til-git-modules-how-to-effectively-remove-submodules/","summary":"While I migrating this website, I came across many issues. One such issue was git submodule.So here is a post on it.\nwhat is a git submodule? Git submodule is a way to include another repository in Git as a sub directory in one repository.\nIt allows you to keep another repo(your own repo or someone else) in your repo as a subdirectory It is useful for track that repo\u0026rsquo;s changes and use that project repo as a reference.","title":"Today I learnt TIL :GIT Modules \u0026 How to effectively remove submodules"},{"content":"It\u0026rsquo;s been a fruitful and amazing year.And that means documenting my small journey as a blog post.\nWork New friends and mentors I joined Boku in September 2021 \u0026amp; had the pleasure to meet some amazing developers and colleagues.\nI got the opportunity to learn a lot while on the job, through mentors, environment \u0026amp; infrastructure itself.\nPromoted to Software Engineer 2 The title says all and I am grateful for it. Without such an awesome environment, I wouldn\u0026rsquo;t have faced the challenges, support and mentorship that I did.\nBlogging Migrating my blog from Jekyll to Hugo I regretted not writing more posts in 2019 even though I had my blog setup on Jekyll . It was not the lack of time that bothered me but more of lack of proper process.\nAs atomic habits books rightly said to develop a habit ,the habit must be easier to execute.After shifting to Doom Emacs this year to make documentation, it made sense to shift my blog from Jekyll to Hugo(Incoming blog post stay tuned!).\nWriting my posts in markdown just for my blog was creating the friction in my writing process. Writing all my posts in .org mode helped me reduced that friction and made my process better.\nAlso by introducing small Today I learnt concepts (tils) posts helped me further in being consistent in writing. As I wrote about the the things I learnt while working and didn\u0026rsquo;t need to invest extra time and effort into researching and writing separate posts.\nLessons learnt: Do one thing at a time One of the biggest lessons I have learnt this year is not to take on too many projects at once .To focus on one thing and to do that properly. I have realised doing too many things at once , made me rush to one project haphazardly so I could complete the next one . This is reminder to myself to complete a project to a satisfactory stage and then move on.\nDocument your software process/journey before/while doing it. Documentation about the work I has always felt like a daunting task to me.But not having proper docs has been more painful.\nOne of key lessons, I am still learning is to make the document while working on the project. To treat writing as a part of the development process and not as an afterthought. One way I recently realised how to do this is to write the titles and subtitles about dos .This helps in breaking down a big problem into a small one. Example: Im trying to put in place this strategy for blog writing too.\nBe organised I found my old diary of 2013 (when I was still preparing for JEE mains ). It showed me a reflection of how I used to organize content for my studies so why not for learning while working and for blogging? This is why I made the decision to learn doom Emacs and vim and use org-mode as a part of being organized. There is a steep learning curve in Emacs. I myself have given up many times on Emacs and have come back because of the useful features it provides.\nDone is better than perfect A lesson I learnt the hard way. All the planning and over thinking can do no good if you don\u0026rsquo;t execute the plan. Just start with an initial plan and start executing it. Putting a little thought into the execution can lead to remarkable results.\nWhat\u0026rsquo;s next? Automation of content creation flow Continuing to refine my blog content creation post workflow, I will explore ways to reach out to wider audience. To do this in such a way that it doesn\u0026rsquo;t take much mental effort from my side. And to find a way to reduce my time and effort in the proof reading \u0026amp; editing process.(Any advice or suggestions are welcome!)\nGetting better at note taking and diagram making One of the key goals for 2023 is taking the effort to make quick diagrams. I have understood concepts quicker by looking at diagrams than reading blocks of text . But diagram making tends to be a long time consuming task. I am currently trying out draw.io and excalidraw for this purpose ,still at experimental stage tho.\nTrying out public speaking or podcast of my learning While explaining a concept to a friend or colleague helped in finding out the gaps in my learning. Though I tried to explain a concept to myself while learning, I tend to find it awkward or sometimes lazy to re-iterate to explain the concept back to myself. One of my goals is to get better at speaking and hopefully not bore my little audience.\nAnd that\u0026rsquo;s all for my year end review for 2022 !\n","permalink":"https://codeklutz.com/posts/my-2022-year-review/","summary":"It\u0026rsquo;s been a fruitful and amazing year.And that means documenting my small journey as a blog post.\nWork New friends and mentors I joined Boku in September 2021 \u0026amp; had the pleasure to meet some amazing developers and colleagues.\nI got the opportunity to learn a lot while on the job, through mentors, environment \u0026amp; infrastructure itself.\nPromoted to Software Engineer 2 The title says all and I am grateful for it.","title":"My 2022 Year Review📓"},{"content":"Today at work once again I had to inspect a json body which was not beautified. Normally I turn to Postman and use the beautify option. But my mac cried and was freezing in instances begging for me to not open more application :( This is where I came across a nifty tool called jq\njq is a lightweight and flexible command-line JSON processor. It is like sed for JSON data. It can used to transform json data into more readableformat. For example :\n❯ echo \u0026#39;{\u0026#34;fullName\u0026#34;: {\u0026#34;firstName\u0026#34;: \u0026#34;Bruce\u0026#34;,\u0026#34;middleName\u0026#34;: \u0026#34;Clark\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Wayne\u0026#34; }}\u0026#39; | jq . { \u0026#34;fullName\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;Bruce\u0026#34;, \u0026#34;middleName\u0026#34;: \u0026#34;Clark\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Wayne\u0026#34; } } Where and why would you use it? There are a few reasons I could think of why I would use jq regularly:\nSimilarly like my situation above, if you want to avoid opening gui apps or online code beautifiers ,this is a great option. Once can prettify a curl output with jq.\nThis is a great option when you pretty json output on the go for example healthcheck urls of your application apis.\ncurl http://example-api-url-you-are-calling.com | jq . curl http://example-api-healthcheck.com/healthcheck | jq . jq is ubiquitous means it is pre-installed in most machines (even cloud vms such as aws and microsoft vms).\nSo next time you want pretty output of a json which is present in an ec2 instance. You dont need to do the manual work of copy and paste and json and figuring it out later.\nAlso I think its pretty secure than the online third party websites developers tend to use to prettify json ,xml while working. Especially when dealing with secret private data which is sometimes pasted on to a random code beautifier website. And pretty handy when you lose internet connection ;) When used in shell scripts , it can save a lot of time and manual effort.\nThis is useful cheat sheet with good example to refer https://lzone.de/cheat-sheet/jq\n","permalink":"https://codeklutz.com/posts/today-i-learnt-til-jq/","summary":"Today at work once again I had to inspect a json body which was not beautified. Normally I turn to Postman and use the beautify option. But my mac cried and was freezing in instances begging for me to not open more application :( This is where I came across a nifty tool called jq\njq is a lightweight and flexible command-line JSON processor. It is like sed for JSON data.","title":"Today I learnt TIL: jq"},{"content":"Today at work once again I had to inspect a json body which was not beautified. Normally I turn to Postman and use the beautify option. But my mac cried and was freezing in instances begging for me to not open more application :( This is where I came across a nifty tool called jq\njq is a lightweight and flexible command-line JSON processor. It is like sed for JSON data. It can used to transform json data into more readableformat. For example :\n❯ echo \u0026#39;{\u0026#34;fullName\u0026#34;: {\u0026#34;firstName\u0026#34;: \u0026#34;Bruce\u0026#34;,\u0026#34;middleName\u0026#34;: \u0026#34;Clark\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Wayne\u0026#34; }}\u0026#39; | jq . { \u0026#34;fullName\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;Bruce\u0026#34;, \u0026#34;middleName\u0026#34;: \u0026#34;Clark\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Wayne\u0026#34; } } Where and why would you use it? There are a few reasons I could think of why I would use jq regularly:\nSimilarly like my situation above, if you want to avoid opening gui apps or online code beautifiers ,this is a great option. Once can prettify a curl output with jq.\nThis is a great option when you pretty json output on the go for example healthcheck urls of your application apis.\ncurl http://example-api-url-you-are-calling.com | jq . curl http://example-api-healthcheck.com/healthcheck | jq . jq is ubiquitous means it is pre-installed in most machines (even cloud vms such as aws and microsoft vms).\nSo next time you want pretty output of a json which is present in an ec2 instance. You dont need to do the manual work of copy and paste and json and figuring it out later.\nAlso I think its pretty secure than the online third party websites developers tend to use to prettify json ,xml while working. Especially when dealing with secret private data which is sometimes pasted on to a random code beautifier website. And pretty handy when you lose internet connection ;) When used in shell scripts , it can save a lot of time and manual effort.\nThis is useful cheat sheet with good example to refer https://lzone.de/cheat-sheet/jq\n","permalink":"https://codeklutz.com/posts/til-jq/","summary":"Today at work once again I had to inspect a json body which was not beautified. Normally I turn to Postman and use the beautify option. But my mac cried and was freezing in instances begging for me to not open more application :( This is where I came across a nifty tool called jq\njq is a lightweight and flexible command-line JSON processor. It is like sed for JSON data.","title":"Today I learnt (TIL): jq"},{"content":"Today while testing a soap API at work, I came across this HTTP error code called HTTP/1.1 422 Unprocessable Entity . According to MDN Web docs, it means the following :\nThe HyperText Transfer Protocol (HTTP) 422 Unprocessable Entity response status code indicates that the server understands the content type of the request entity, and the syntax of the request entity is correct, but it was unable to process the contained instructions.\nIt means that the syntax of the request is correct and well-formed but it has semantic, logical errors. Meaning the soap body xml format will be correct but the issue arises because of the content inside the XML tags*. In this case, it could be the following:\nWrong character within the code. The server doesn’t understand the content within a particular XML tag. Or it refuses to process any other content inside the tag other than a fixed decided value). Difference between 422,404 and 415 Error codes .Permalink According to RFC,\nThe 422 (Unprocessable Entity) status code means the server understands the content type of the request entity (hence a 415(Unsupported Media Type) status code is inappropriate), and the syntax of the request entity is correct (thus a 400 (Bad Request) status code is inappropriate) but was unable to process the contained instructions. For example, this error condition may occur if an XML request body contains well-formed (i.e., syntactically correct), but semantically erroneous, XML instructions.\nIn testing a soap API, the content type of the request body was correct. I checked for Content-Type header while testing) – Hence 415(Unsupported Media Type) was not valid. For soap,it was Content-Type: text/xml; charset=UTF-8. And the syntax of the request body was also correct– Hence 404(Bad request) was not valid.\nThe error occurred due to an incorrect value in the XML tag in my case. Value should have been \u0026lt;ns8:exampleTag\u0026gt;123\u0026lt;/ns8:exampleTag\u0026gt; instead of \u0026lt;ns8:exampleTag\u0026gt;456\u0026lt;/ns8:exampleTag\u0026gt;\n","permalink":"https://codeklutz.com/posts/today-i-learnt422-http-error-code/","summary":"Today while testing a soap API at work, I came across this HTTP error code called HTTP/1.1 422 Unprocessable Entity . According to MDN Web docs, it means the following :\nThe HyperText Transfer Protocol (HTTP) 422 Unprocessable Entity response status code indicates that the server understands the content type of the request entity, and the syntax of the request entity is correct, but it was unable to process the contained instructions.","title":"Today I learnt:422 HTTP Error code"},{"content":"I came across a fascinating Java talk on youtube by Devoxx 2022 Hanno Embregts. This article is about a few java snippets I encountered. The purpose of today’s TIL is to have a list of interesting things we could do in Java and not deep dive into each concept.\nToday’s TIL : Crazy things to do with Java 11+\nInitializing Array and var keywordPermalink Having the var keyword in a statically typed language such as Java was fascinating in itself(an article on this in the future :). But we never thought we would use it to initialize such as\nvar element =new int[2]; //WORKS var [] element=new int[2]; // COMPILE ERROR :error: \u0026#39;var\u0026#39; is not allowed as an element type of an array Since var is a generic element type, giving it array [] provides an error since rather than being generic we are giving it an array type. C style ArrayPermalink What is a c style array? Java supports providing [] before and after the variable name in an array\nint []arr=new int[2]; int arr1[]=new int[2]; In C style array, we provide [] after the variable name that is ~int arr1[].\nSo in Java, suppose we have the following code:\nint arr1[],arr2; arr1=new int[1]; arr2=new int[1]; //COMPILE ERROR : error: incompatible types: int[] cannot be converted to int The above code will result in COMPILE ERROR for arr2 since arr2 is not an array but a primitive int variable. But if we want to want both arr1 and arr12 as array type we need to change the declaration to\nint [] arr1,arr2; //Notice how [] are arr1=new int[1]; arr2=new int[1]; Arrays.asList and Primitives Let’s look at the following example :\nString [] strArr={\u0026#34;one\u0026#34;,\u0026#34;two\u0026#34;,\u0026#34;three\u0026#34;}; var stringList= Arrays.asList(strArr); int [] intArray = {1,2,3}; var intList = Arrays.asList(intArray); System.out.println(stringList.contains(\u0026#34;one\u0026#34;)+\u0026#34; \u0026#34;); System.out.print(intList.contains(1)); Output: true false Signature of Arrays.asList is var-args or List of T’s.\npublic static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; asList(T... a) T is of generic type so that means it needs to reference a Type such as Integer,Float and not reference Array of Ints\nBut next question is Can they boxed ? (Autoboxing: Converting primitive to Class Type example : int -\u0026gt; Integer) Answer is no Array of ints -\u0026gt; Cannot be boxed -\u0026gt; Array of Integer\nDon’t use Arrays.asList on primitives\nNo structural changes allowed in ArrayPermalink String [] ints ={\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;,null}; List\u0026lt;String\u0026gt; strings= Arrays.asList(ints); strings.removeIf(Objects :: isNull); System.out.println(strings.size()); Output: Exception in thread “main” java.lang.UnsupportedOperationException: remove at java.base/java.util.Iterator.remove(Iterator.java:102) Because the array does not allow any structural changes to it\nA Unique way to remove null values from Map Map\u0026lt;Integer,String\u0026gt; map=new HashMap(); map.put(4,null); //currently map has key:4 value: null System.out.println(map.getOrDefault(4,\u0026#34;four\u0026#34;)); map.putIfAbsent(4,\u0026#34;four\u0026#34;); //key key:4 value:four System.out.println(map.get(4)); Output: null,four ##\nvar numbers = List.of(-1,0,1); Map\u0026lt;Integer,List\u0026lt;Integer\u0026gt;\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); numbers.forEach(number-\u0026gt; map.putIfAbsent(number,new ArrayList\u0026lt;\u0026gt;()) .add(number)); System.out.println(map.get(0)); Output: NullPointerException: Exception in thread “main” java.lang.NullPointerException at HelloWorld.lambda$main$0(HelloWorld.java:33) Because map.putIfAbsent returns null if no value is present\n","permalink":"https://codeklutz.com/posts/today-i-learnt-interesting-things-in-java-11/","summary":"I came across a fascinating Java talk on youtube by Devoxx 2022 Hanno Embregts. This article is about a few java snippets I encountered. The purpose of today’s TIL is to have a list of interesting things we could do in Java and not deep dive into each concept.\nToday’s TIL : Crazy things to do with Java 11+\nInitializing Array and var keywordPermalink Having the var keyword in a statically typed language such as Java was fascinating in itself(an article on this in the future :).","title":"Today I learnt: Interesting Things in Java 11"},{"content":"Upon stumbling upon this motivating HN post by Simon Willison I have been inspired to start a Today I learnt(TIL) series of my own. This seems like a doable promising idea where I do not have the self-imposed pressure of researching for a blog idea and making a seperate time to write that specific post. Wrting this TIL flows naturally in day-to-day work flow where I could just say “Hey I just learnt about this XYZ ,I should write about it”.\nStarting with Today’s TIL : Database Version Control\nWhat it is : A practice or form of maintining and tracking every change made to database schema, just like git version control(But this is specifically for Database). It acts like a single source of truth (like a git code repository)\nThis concept solves a lot of problems we face as developers such as :\nAs a developer,One must have faced a situation where to solve a particular problem statement or feature , you need to do database changes,however for those changes to reflect application needs to be restarted or you might have database and application code changes, an organization already has some processes defined for deployment. In development phase, one usually runs the db changes or sql queries in local generally via a sql client application.For example,Update some existing db property.\nBut for that same change to be reflected in production db, CICD processes are define fdd for deployment or a seperate team might be responsible for deployment altogether.Hence we cant expect a seperate db team to always be in sync with deployment team or that particular CICD process. Hence, DB schema changes should be deployed as a part of application code changes.\nThis is where database version control comes in handy where :\nYou need traceability and a commit history of db schema changes done before. Protect prodcution database tables from unwanted or uncontrolled changes Help in communication between teams regarding data(where a member can look at the query and provide feedback as a part of Pull request) Applications such as liquidbase,flyway scripts come in handy Speaking of liquibase which works on changelog concept where you have\nA Changelog file which inside has -\u0026gt; ChangeSet (which are used to define Db changes)- \u0026gt; Which can include SQL Queries and Rollback queries if the changes dont work in that specific environment.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;databaseChangeLog xmlns=\u0026#34;http://www.liquibase.org/xml/ns/dbchangelog\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:ext=\u0026#34;http://www.liquibase.org/xml/ns/dbchangelog-ext\u0026#34; xmlns:pro=\u0026#34;http://www.liquibase.org/xml/ns/pro\u0026#34; xsi:schemaLocation=\u0026#34;http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-latest.xsd http://www.liquibase.org/xml/ns/dbchangelog-ext http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-ext.xsd http://www.liquibase.org/xml/ns/pro http://www.liquibase.org/xml/ns/pro/liquibase-pro-latest.xsd\u0026#34;\u0026gt; \u0026lt;changeSet id=\u0026#34;1\u0026#34; author=\u0026#34;XYZ\u0026#34;\u0026gt; \u0026lt;comment\u0026gt; \u0026lt;/comment\u0026gt; \u0026lt;sql\u0026gt; INSERT INTO Exampledb.exampletable(\u0026#39;id\u0026#39;,\u0026#39;name,\u0026#39;serial\u0026#39;) VALUES(\u0026#34;1\u0026#34;,\u0026#34;test\u0026#34;,\u0026#34;serial\u0026#34;); \u0026lt;/sql\u0026gt; \u0026lt;rollback\u0026gt; DELETE FROM Exampledb.exampletable where id=\u0026#34;1\u0026#34;; \u0026lt;/rollback\u0026gt; \u0026lt;/databaseChangeLog\u0026gt; This changelog file needs to be included in a master changelog file which consists a list of all change log files (Similar to how a git commit history consists of all commit ids)\n","permalink":"https://codeklutz.com/posts/today-i-learnt-database-version-control/","summary":"Upon stumbling upon this motivating HN post by Simon Willison I have been inspired to start a Today I learnt(TIL) series of my own. This seems like a doable promising idea where I do not have the self-imposed pressure of researching for a blog idea and making a seperate time to write that specific post. Wrting this TIL flows naturally in day-to-day work flow where I could just say “Hey I just learnt about this XYZ ,I should write about it”.","title":"Today I learnt: Database Version Control"},{"content":"After a long series of procrastination and getting the hit of motivation from reading Atomic Habits(great book which I recommend others) ,I’m finally learning kubernetes basics.As a motivator to get better at writing and publish more posts as well as learn kubernetes.I have decided to publish 1 article every Sunday.I would like to post 2 posts per week but I want to start small and consistent. Once again I’m treating my blog as a journal to showcase how much I actually understand kubernetes.Also its quite handy to have my own notes on a site. So here is a blog post on kubernetes basics part 1.This will be a multi part series. Before we begin some pre requisites which one needs to know :-\nPre requisite You should be already familiar and comfortable with the concept of containers and container run-time such as docker as kubernetes is for managing different containers and their deployment at a large scale.Another point which is not mandatory but good to know would be basic docker commands like docker run etc.\nWhat is kubernetes? Kubernetes is an open-source technology that is used for container orchestration. And what is container orchestration exactly? It is the process of continuous deployment ,scaling and management of containers.\nLets first look at the kubernetes architecture and the individual components in it.\nNode: A Node is either a physical or virtual machine on wihc kubernetes is installed. A node is like a worker machine on which containers (having our application) will be running by Kubernetes.And like any other machine ,nodes can crash for a number of reasons ;) .So once the node crashes the application will be go down as well. So tackle this we need multiple nodes rather than 1 node.\nAnd mulitple nodes come together to form a group known as the cluster.So even if one node inside the cluster fails,we have our application accessible and running from the other nodes.Plus it helps in sharing load!\n* Master Node : So now we have our cluster running on a group of nodes which are running our containerised apps.But who is responsible to manage this cluster:?Also when a node goes down how to direct the traffic of the failed node to other working nodes?Also who stores the information about these worker nodes stored? and How are the nodes monitored?\nThe master node!\nThe master node is another machine with kubernetes installed in it and it watches over the nodes and does the actusl orchestration of the worker nodes.\nNote that a cluster can have multiple master nodes depending on the size of the cluster.\nbecause at the end of the day , a master node is a machine (which can crash) and for high availability we need to avoid that.\nOther components: When you install kubernetes in your system,you are actually installing the follwing components:\nAn Kube api server (Master) An etcd service (Master) -A kubelet service (Worker)\nController (Master) Scheduler (Master) Container Runtime Kube API server: Kubeapi server acts as a frontend for kubernetes.The users,commandline tools,managment devices all interact with the cluster via the Kube API server.\netcd etcd is a distributed key value store used to store data about how to manage the cluster.It is also resp0onsible to implement logs within the cluster to ensure there is no conflict between mulitple masters.\nNote that your application data is not stored in etcd only logs and information about the cluster.\nScheduler Scheduler is responsible is distributing containers across multiple nodes.It looks for newly created containers and assigns them to nodes.\nControllers Controllers are the brain behind the orchestration. They are responsible for notcining and responding nodes,containers or endpoint goes down.The controller takes decsions to bring up new nodes in this case.\nContainer Runtime The container runtime is the underying software that runs the containers.Most of the times,its docker.I have used docker but there are other runtimes such as CRI-O\nKubeletPermalink Kubelet is an agent that runs on each worker node in the cluster. The agent is in charge of making sure that containers are running on the nodes as expected.\nMaster vs Worker nodesPermalink So now we know there are 2 types of nodes : Masternode and Worker node. How does a node become master or a worker node? A worker node has the containers are hosted and running .Hence to run these containers we need a Container Runtime such as docker installed in these machines.\nThe master has a kube API server and this is what differentiates the master from worker nodes. The worker node have the kubelet agent that interacts with the master to proivide health information about the worker nodes and carries out the instrcutions given by the master node on worker nodes.The master has all this information stored in key value store (etcd) known as the etcd.The master also has the controller and scheduler.\nKubectlPermalink kubectl is a commandline tool is used to deploy and manage applications in a cluster.Basically we are going to use these commands from the kubectl tool to get us information (kubectl get,status describe) about the nodes and other components in the cluster and to manage many other operations.\nkubectl run –Used to deploy an application onto the cluster\nkubectl get cluster-info –Used to fetch the cluster information\nkubectl get nodes –Used to fetch information about nodes.\nThat is all on basic overview.Next article will be focused on pod and how pods work in nodes in kubernetes.\n","permalink":"https://codeklutz.com/posts/tackling-procrastination-and-kubernetes-study/","summary":"After a long series of procrastination and getting the hit of motivation from reading Atomic Habits(great book which I recommend others) ,I’m finally learning kubernetes basics.As a motivator to get better at writing and publish more posts as well as learn kubernetes.I have decided to publish 1 article every Sunday.I would like to post 2 posts per week but I want to start small and consistent. Once again I’m treating my blog as a journal to showcase how much I actually understand kubernetes.","title":"Tackling procrastination and kubernetes study"},{"content":"I tried a lot of things in January not necessarily everything learnt was used and and not every side project which I worked on got live.\nHowever I learnt many lessons from my own failures and gained more insights when I started some initiatives. So just a small gist of looking back on January and mid February.\nMy Blog! codeklutz.com I have been wanting to make my own tech blog for a while now but I needed something which didn’t necessary requires much code or db maintenance.I didn’t want to opt for WordPress for the same reason.\nJekyll with GitHub pages is a life saver here! Also learnt a lot on custom domains after buying my own domain,about Google analytic and SEO.Plus customising Jekyll site with themes has been fun.\nLetters to me This idea struck me in the wee hours at night.I always get some random tech ideas or where I am curious about something and think about it as to how I would do this particular task.\nI think of this site as an idea jar 💡 or tech journal 📝 where I jot down my wacky, scrambling thoughts.Something which I can look back on for ideas when I don’t feel creative or as starting thinking point for my small side projects.Some tech thoughts which aren’t polished enough for a blog but are useful tiny ideas which provide insight. Also since it’s on the internet maybe someone might find it useful or insightful? I’m thinking of adding an rss feed to this in the future if anyone would be interested in following this.\nExpiermenting with audio in blogs Based on the idea mentioned in letters.codeklutz.com decided to implement an audio feature for this blog.I tried finding some open source or free alternative.And I did find one but sadly this one proved to be a failure at the current moment.\nThe audio is decent but the voices which I found are too mechanical and monotonous to listen continuously.I shall still try finding some open source alternative because I don’t want to invest in paid alternatives for this small blog at the moment.\nNoteKlutz https://note.codeklutz.com This mini project is again a part of implementation of the idea mentioned in letters.codeklutz.com It already proving to be useful;) I realised I write more markdown (for creating study notes +writing this blog) so I felt the need to create my own editor which is suited for myself and at the same time not fear giving my data to someone or idk?(lmao)\nBut main focus was not to use another app just to create notes and since I use browser more than anything else this seemed like a good idea\nIt’s a small,minimal project which does exactly what I need it to do and does it right (at least for me biased here🤫) It’s like my second organising brain 🧠.The code is an absolute mess and needs heavy work which I will do my pushing small updates on weekends🤭.\nSo this was all for January and Mid Feb\n","permalink":"https://codeklutz.com/posts/tech-recap-journal-january/","summary":"I tried a lot of things in January not necessarily everything learnt was used and and not every side project which I worked on got live.\nHowever I learnt many lessons from my own failures and gained more insights when I started some initiatives. So just a small gist of looking back on January and mid February.\nMy Blog! codeklutz.com I have been wanting to make my own tech blog for a while now but I needed something which didn’t necessary requires much code or db maintenance.","title":"Tech Recap Journal- January📓"},{"content":"avigation, editing, development using terminal and zsh . But recently due to unforeseen updates, my bios was messed up big time which has led me unable to install Linux for the time being. But the work and learning never stops and nor shall I ! ☺ I don’t hate windows but it’s definitely not my first choice for development and coding after discovering Linux.🤭\nBut Thanks to WSL, windows terminal, and the beautiful zsh .I can get that Linux experience on windows!\nSo this is just a blog post on how I customized my terminal on windows 10 using wsl, windows terminal,zsh, and many more fun plugins which I use on my Linux as well as windows for development(work or home). What is wsl? It stands for windows subsystem for Linux and it\u0026rsquo;s a feature of Windows that allows developers to run Linux file systems,command-line tools etc directly on windows!(Goodbye painful windows mouse navigation) First, you need the wsl feature on windows 10 by going to Start -\u0026gt;Type windows feature on search and below checkbox should be checked for enabling windows subsystem for Linux. Now you need to install wsl which you can by going Start-\u0026gt; Microsoft store -\u0026gt;type ubuntu.Im installing Ubuntu wsl since I\u0026rsquo;m familiar with it you can also change distros. I\u0026rsquo;m also installing another app called windows terminal because it\u0026rsquo;s much better in terms of ui to me as compared to Ubuntu terminal.This is optional. At this point, it\u0026rsquo;s your choice whether you want to continue with the Ubuntu terminal or use the windows terminal.If you decide with the former,skip the next para and if you decide with the latter then you need to set windows terminal as your default shell. Now by default windows terminal opens the power shell, to set to Ubuntu Go to settings as shown below\nNow you have a Ubuntu shell that has bash. I personally use zsh with OhMyZsh for my work for that beautiful productivity. Using OhMyZsh features like navigating without using cd, usage of ll, easier tab-click based navigation, and much more!\nNote that zsh and OhMyZsh are different. When you install OhMyZsh, many plugins come with it for your rescue! So to install zsh. Update the libraries first then install zsh.\nsudo apt-get install update sudo apt install -y zsh Then Install ohmy zsh\nsh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; Now your previous~/.zshrc config will be replaced by ohmyzsh To customize the shell next install powerlevel10k.\ngit clone - depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k This command clones the repo and now go to your ~/.zshrc and set the theme as power level 10k And then\nsource ~/ .zshrc Note: To reflect every change you make, do source ~/.zshrc in the terminal. And then this will give you a set of options to configure which you can decide for your customization.\nMy favourite plugins I use these plugins daily and they make my life super smooth !\nFzf It\u0026rsquo;s a fuzzy finder command-line tool that lets your fuzzy find anything (files directories git branches you name it )across file system. You can use ti write your custom fuzzy find scripts to find anything.I have posted a link if my current config and aliases for reference. Clone the repo from any directory and just run the install script.\ngit clone - depth 1 https://github.com/junegunn/fzf.git ~/.fzf ~/.fzf/install Here is a small example of small WIP config for reference.\nZsh Auto-suggestions This one Autocompletes while you type a command.This is useful especially when you type commands which you use daily but need to to try multiple times such as navigating and printing log at a specific long location. Git Clone the zsh-autocomplete plugin in the OhMyZsh plugin folder.\n$ sudo git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions Once that is done, add the plugin in the ~/.zshrc file\u0026rsquo;s plugin list.\nplugins=( … zsh-autosuggestions ) Zsh Syntax highlighting This one automatically highlights zsh commands as you type. This saves a lot of typing on my part. Git Clone the zsh-syntax-highlighting plugin in the OhMyZsh plugin folder.\n$ sudo git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting And once again add it to the plugins list of the .zshrc file.\nplugins=( … zsh-syntax-highlighting ) Note: To reflect every change you make, do source ~/.zshrc in the terminal.\nReadymade Github Aliases from Oh My Zsh Usually one defines short github aliases such as g.b forgit branch or g.c for git checkout in ~/.zshrc but you know by using ohMyZsh already has a list of easy git aliases configured. The format is first 2–3 letters of the first letter of the command such as\ngb git branch List of local branches gba git branch -a List of local and remote branches gcam git commit -am Add all files to stage and commit gcmsg git commit -m Git commit message gco git checkout Change branch gco - git checkout to the previous branch Change branch to the previous one gd git diff Files differences in staging gfa git fetch - all - prune Fetch all remote branches, delete branch if upstream is gone gl git pull Pull from remote gp git push Push to remote gpsup git push - set-upstream origin [currentbranch] Set upstream branch gst git status Local files to commit I use these git aliases daily and they make working super fun.I recommend going through oh-my-zsh git aliases cheatsheets\nThat\u0026rsquo;s all folks! This is my current setup in windows for development and this is still a work in progress that can keep changing but these plugins and zsh are something that has made the experience of using windows quite fun.\n","permalink":"https://codeklutz.com/posts/making-peace-with-windowsinstalling-wslzshpowerlevel10kfzf-many-more-fun-plugins-for-easy-development/","summary":"avigation, editing, development using terminal and zsh . But recently due to unforeseen updates, my bios was messed up big time which has led me unable to install Linux for the time being. But the work and learning never stops and nor shall I ! ☺ I don’t hate windows but it’s definitely not my first choice for development and coding after discovering Linux.🤭\nBut Thanks to WSL, windows terminal, and the beautiful zsh .","title":"Making Peace with Windows!Installing wsl,zsh,powerlevel10k,fzf \u0026 many more fun plugins for easy development"},{"content":"These days I am more into creating backend projects which include microservices.But if anyone wants to test these services one needs postman or do the old classic way of curl command.\nBoth do the job brilliantly but what if I wanted some user who doesn’t want to install postman or use curl and still wants to test my live APIs thru the browser? I came across this swagger open API specification and this is a really handy tool!\nIn layman’s terms, Swagger OpenAPI specification provides API documentation for REST APIs. An OpenAPI file allows you to describe all the APIs within the project and even lets you try out the APIs!\nAvailable endpoints can be /projectApi and all operations on each endpoint which can GET /getProjectApi , POST /insertProjectApi , DELETE /deleteProjectApi .\nAlso, integration of swagger open API is pretty painless in spring boot and it lets users try out the APIs within the browser without any installation of any software from the user (sounds pretty convenient and sweet to me)\nIn this post, I will describe how I integrated swagger open API in Spring boot project.First you need a spring boot project having basic dependcies using Spring Initializr https://start.spring.io/ or you could use this project used in the example here\nFirst add the springdoc-openapi-ui dependency to pom.xml:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springdoc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springdoc-openapi-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; Then run the application and check the below url to check open api specification\nhttp://localhost:8080/v3/api-docs/ You should be able to see something like this You can also add a custom path by adding entry in application.properties file\nspringdoc.api-docs.path=/api springdoc.swagger-ui.path=/swagger springdoc.swagger-ui.operationsSorter=method Check http://localhost:8080/swagger for web UI.To show you in this example we have a following apis in the controller\npackage com.TestDocker.BooksDocker.Controllers; import java.util.List; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpStatus; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.server.ResponseStatusException; import com.TestDocker.BooksDocker.Models.Book; import com.TestDocker.BooksDocker.Repository.BookRepository; @RestController public class MainController { @Autowired public BookRepository bookRepository; @GetMapping(\u0026#34;/test\u0026#34;) public String test() { return new String(\u0026#34;Working from DOcker Bopoks proj \u0026#34;); } @GetMapping(\u0026#34;/\u0026#34;) public List\u0026lt;Book\u0026gt; fetchAllBooks() { List\u0026lt;Book\u0026gt; books; try { books = bookRepository.findAll(); } catch (Exception ex) { throw new ResponseStatusException(HttpStatus.INTERNAL_SERVER_ERROR, \u0026#34;Error occured in fetchAllBooks\u0026#34;, ex); } return books; } @GetMapping(\u0026#34;/{bookID}\u0026#34;) public Book fetchBookfromID(@PathVariable(\u0026#34;bookID\u0026#34;) Long bookID) { Book book; try { book = bookRepository.getById(bookID); } catch (Exception ex) { throw new ResponseStatusException(HttpStatus.INTERNAL_SERVER_ERROR, \u0026#34;Error Occured in fetchBookfromID\u0026#34;, ex); } return book; } @GetMapping(\u0026#34;/search/{title}\u0026#34;) public List\u0026lt;Book\u0026gt; searchBookByTitle(@PathVariable(\u0026#34;title\u0026#34;) String title) { List\u0026lt;Book\u0026gt; books; try { //System.out.println(title); books = bookRepository.fuzzySearchByTitle(title); System.out.println(books); } catch (Exception ex) { throw new ResponseStatusException(HttpStatus.INTERNAL_SERVER_ERROR, \u0026#34;Error Occured in searchBookByTitle\u0026#34;, ex); } return books; } @PostMapping(\u0026#34;/insertBooks\u0026#34;) public String insertBooks(@RequestBody List\u0026lt;Book\u0026gt; books) { for (Book b : books) { System.out.println(b.toString()); Book b1 = bookRepository.save(b); if (b1 == null) return \u0026#34;Book object is null\u0026#34;; } return null; } } So the swagger ui look something like this. Also json docs will be available at http://localhost:8080/api springdoc.swagger-ui.operationsSorter=method sorts the API paths in order of their HTTP methods. You can try and test the apis from web ui too.It also shows schema information! Overall this is a much convenient way of setting up documentation for your apis which can be handy in some situations.\nThat’s all folks!\n","permalink":"https://codeklutz.com/posts/integrating-swagger-openapi-for-easy-api-documentation-in-spring-boot/","summary":"These days I am more into creating backend projects which include microservices.But if anyone wants to test these services one needs postman or do the old classic way of curl command.\nBoth do the job brilliantly but what if I wanted some user who doesn’t want to install postman or use curl and still wants to test my live APIs thru the browser? I came across this swagger open API specification and this is a really handy tool!","title":"Integrating Swagger OpenAPI for easy API documentation in spring boot"},{"content":"I was recently studying about using cron jobs in spring boot for a particular use case for my small side project. I ended up not using the cron job but rather went the SQL way(will explain this in detail below). However,in the process I learnt a lot about cron jobs and scheduling in spring boot so this is just a small article about my learnings.\nBut first I shall tell you a little about my use case and why I thought about cron jobs in the first place…..\nUse case My application was inserting data (let’s call it smash data for simplicity for now)in the database.Each smash data has a certain expiry period and after that expiry period, that data should no longer remain in the database.But the expiry period will be different for each smash data.\nExample:\nsmash 1, expiryperiod :10mins\nsmash 2 ,expiryperiod :60mins\nsmash 3 ,expiryperiod :150mins . . . etc.\nNow my first line of thinking ended up being cron jobs which led to me studying about cron jobs and scheduled in spring boot.To answer it simply I didn’t end up taking this route is because cron jobs or scheduled tasks are suited when we expect the task to execute at only a particular point of time or where we expect functionality to be executed at w particular time on an hourly/daily /weekly/monthly basis. I could get the cron job to delete the data but to delete WHICH data smash 1 or smash 2? That would mean I would have to check the DB. So the process would be something like:-\nFetch all rows from DB. Check timestamp of each row data against current timestamp and delete accordingly. I wanted to avoid writing the searching, comparing time logic (dates, in general, can be a pain sometimes).The logic which I did ended up going through was events in SQL since I’m using MySQL db for the use case\nMysql events are tasks that run according to a particular schedule …hence they can be called as scheduled events\nWhen an event is created in MySQL, a named database object is created and this object consists of one or more SQL statements to be executed at some regular intervals.Using events,I didn’t have to retrieve and search the data (as I had to do in the spring boot controller ) . I could just write an event such as\nDelete from table1 where expiry period \u0026lt; NOW(); And schedule this to execute every minute. Which was would check for that expiryPeriod column in each row and compare with time NOW() So any rows whose expiryperiod has passed will be deleted from db.\nThe only thing to note I see in this approach, for now, is that this is database dependent so when I host this side project (a hopeful dream) I need to make sure events is configured for the same. So this was the use case now back to cron jobs!\nCron jobs or schedule tasks in spring boot.Permalink When a situation arises where we expect the task to execute at only a particular point of time or where we expect functionality to be executed at a particular time on an hourly/daily /weekly/monthly basis. Cron jobs are suitable for this use case. In spring this sort of scheduled task can be achieved through @Scheduled annotation.\nThere are a few rules while using the @Scheduled annotation: 1. The method should typically have a void return type else the returned value will be ignored.\nthe method should not expect any parameters. First, to enable scheduling in the spring boot project, use @EnableScheduling in the main class.\npublic class Application { public static void main(String[] args) { SpringApplication.run(PasteBinApplication.class, args); } } Scheduling using CRON expressions @Component public class SchedulerService { @Scheduled(cron=\u0026#34;*/15 * * * * ?\u0026#34;) public void testScheduled() { System.out.println(\u0026#34;Method executed at every 15 seconds. Current time is :: \u0026#34;+ new Date()); } } A guide for cron jobs: cron Image source :Java Techonline SEC MIN HOURS DAY MONTH WEEKDAY * * * * * * Scheduling using initial delay,Fixed Delay or Fixed Rate The main difference between Fixed Delay and Fixed Rate is : Fixed Delay : controls the next execution time when the last execution finishes. Fixed Rate : makes Spring run the task on periodic intervals even if the last invocation may be still running.\nFixed Delay\n@Component public class SchedulerService { @Scheduled(fixedDelay = 1000, initialDelay = 5000) public void testScheduled() { System.out.println(\u0026#34;Method executed with fixed delay and initial delay . Current time is :: \u0026#34;+ new Date()); } } Also Fixed Delay can take input in String and Integer. @Scheduled(fixedDelayString = “7000”) @Scheduled(fixedDelayString = 7000) Fixed Rate:\n@Component public class SchedulerService { @Scheduled(fixedRate = 1000) public void testScheduled() { System.out.println(\u0026#34;Method executed with fixed rate . Current time is :: \u0026#34;+ new Date()); } } That’s all folks.Learning about events and cron jobs and where could be applied was interesting to learn when applied on some small practical application.\n","permalink":"https://codeklutz.com/posts/which-would-you-go-for-spring-boot-cron-jobscheduled-tasks-vs-events-in-mysql/","summary":"I was recently studying about using cron jobs in spring boot for a particular use case for my small side project. I ended up not using the cron job but rather went the SQL way(will explain this in detail below). However,in the process I learnt a lot about cron jobs and scheduling in spring boot so this is just a small article about my learnings.\nBut first I shall tell you a little about my use case and why I thought about cron jobs in the first place….","title":"Which would you go for? Spring boot cron job,scheduled tasks vs Events in Mysql."},{"content":"I deployed my portfolio site and wanted to try out github actions and this is my experience of automating the deployment. This article is more focused on how you can use the GitHub actions and how easy it is to deploy your code to GitHub pages rather than the portfolio site code.So every time you make an update or build to your website ,the changes are automatically reflected and this automated deploying process makes work much faster.\nThe way GitHub action works is you create actions in your repositories by creating one or more yaml files and these are called workflows.Workflows now can handle build tasks like CI CD. This means you use the action to test your code and push the site to the desired hosting platform (in this case GitHub pages ) when the main branch changes . First step assuming that you have a GitHub account is to create a repository having your website code in it.Now I have a bootstrap website but in the future I do plan on adding node JS so I already added package.json.\n{% gist 7fc9e560ec958d6fb9876019e298e02f %}\n{ \u0026#34;name\u0026#34;: \u0026#34;shwetarkadam.github.io\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Portfolio\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.html\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;npm run clean \u0026amp;\u0026amp; npm run imagemin \u0026amp;\u0026amp; npm run copyfonts \u0026amp;\u0026amp; npm run copydata \u0026amp;\u0026amp; npm run usemin\u0026#34;, \u0026#34;clean\u0026#34;: \u0026#34;rimraf dist\u0026#34;, \u0026#34;copyfonts\u0026#34;: \u0026#34;copyfiles -f node_modules/font-awesome/fonts/* dist/fonts\u0026#34;, \u0026#34;copydata\u0026#34;: \u0026#34;copyfiles -f src/js/* dist/js\u0026#34;, \u0026#34;imagemin\u0026#34;: \u0026#34;imagemin src/img/* -o dist/img\u0026#34;, \u0026#34;lite\u0026#34;: \u0026#34;lite-server\u0026#34;, \u0026#34;start\u0026#34;: \u0026#34;npm run lite\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34;, \u0026#34;usemin\u0026#34;: \u0026#34;usemin index.html -d dist --htmlmin -o dist/index.html\u0026#34; }, \u0026#34;repository\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;git@github.com:shwetarkadam/portfolio.git\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;Shweta Kadam\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;MIT\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;bootstrap\u0026#34;: \u0026#34;^4.4.1\u0026#34;, \u0026#34;font-awesome\u0026#34;: \u0026#34;^4.7.0\u0026#34;, \u0026#34;jquery\u0026#34;: \u0026#34;^3.5.1\u0026#34;, \u0026#34;popper.js\u0026#34;: \u0026#34;^1.16.0\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;copyfiles\u0026#34;: \u0026#34;^2.2.0\u0026#34;, \u0026#34;imagemin-cli\u0026#34;: \u0026#34;^5.1.0\u0026#34;, \u0026#34;lite-server\u0026#34;: \u0026#34;^2.5.4\u0026#34;, \u0026#34;rimraf\u0026#34;: \u0026#34;^3.0.2\u0026#34;, \u0026#34;usemin-cli\u0026#34;: \u0026#34;^0.6.0\u0026#34; } } Verify all your changes as correct by first in your root folder running the command:\nnpm install npm install\nand after installing node modules run the command:\nrun npm start so you should get your output in localhost something like this\nNow that you have ensured that the project runs properly in your local machine,it is ready to be deployed to GitHub pages. You will only need to commit and push your changes to the main branch of a repo and ensure that the settings are pointing to the correct branch to display a site for that. Now the file that does this is that deploy.yml file which we will use to create the workflow.\nname: Build and Deploy on: push: branches: - main jobs: build-and-deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 with: persist-credentials: false - name: Install and 06Build run: | npm install npm run build - name: Deploy uses: JamesIves/github-pages-deploy-action@releases/v3 with: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} BRANCH: gh-pages FOLDER: dist Now this yaml file which can be found .github/workflows/deploy.yml file in local ,you can rename the file whatever you like.It tells the github actions to install the project dependencies run a build script and put that required files in a output folder name dist and upload the contents of the dist folder to the gh-pages branch and if the branch does not exist it will create that branch.The workflow to deploy the site to github-pages you can find that from James Ives GitHub pages deploy action. If you have any existing site or code and you want to publish it to get pages you only need this file to be added into your project. You could go to your github repo Actions Tab -\u0026gt; Create Simple Workflow and copy paste the above content in your yaml file.\nOnce you have a site ready for GitHub Pages, and your project includes the .github/workflows/deploy.yml file, you only need to commit and push your changes to the main branch of your repository. You can the ongoing workflow by going to Actions=\u0026gt;build and deploy.Also this is the place where you can debug what went wrong in case your workflow fails.\nAfter the GitHub Actions have run, ensure settings are pointing to the correct branch to display your site. Go to the settings of your repository and ensure that the source for GitHub Pages is using the correct branch. It is close to the bottom of the main settings page.\nIt does take some time at the start to load in the browser but once available you can click on the link in the green bar above. Now every time you make a push to the main branch ,the changes are reflected in the main site.\nMy Portfolio Site: Click Here\nThat’s all folks. Happy Learning.\n","permalink":"https://codeklutz.com/posts/deploying-my-portfolio-website-for-free-on-github-pages-using-github-actions/","summary":"I deployed my portfolio site and wanted to try out github actions and this is my experience of automating the deployment. This article is more focused on how you can use the GitHub actions and how easy it is to deploy your code to GitHub pages rather than the portfolio site code.So every time you make an update or build to your website ,the changes are automatically reflected and this automated deploying process makes work much faster.","title":"Deploying my portfolio website for free on Github Pages using GitHub actions"},{"content":"Just revisiting and explaining myself Polymorphism concept here through a blog post. The words Polymorphism means multiple forms.\nIn Java ,Polymorphism means multiple forms of an object. We shall divide this article into 3 sections.\n1.Syntax\n2.Calling a variable polymorphically.\n3.Calling a method polymorphically.\n1.SyntaxPermalink Now in polymorphism in Java, the thumb key rule to remember is\nsuper = subPermalink Meaning the variable reference (LHS) must always be a super class reference and the object initialization(RHS) must a sub class.\nFor Example: class A{\n} class B extends A{ } class C extends B{ } class D extends A{ }\nSo valid and invalid syntax according to the thumb rule will be\nA a =new B(); //VALID B b=new D(); //NOT VALID C c=new A(); //VALID A a1=new D(); //VALID 2.Calling a variable polymorphically.Permalink If a variable is called from a polymorphic object,we follow the reference i.e. the super class. And if the variable is not present in the super class ,it results in a COMPILE ERROR. EG:\nclass A{ int x=5; } class B extends A{ int x=10; } class App{ public static void main(String[]args){ A a=new B(); System.out.println(a.x); //What do u think is the output class A x value (5)or class B x value(10)?Follow the rule. } } OUTPUT: 5 Calling a method polymorphically.Permalink If a method is called from a polymorphic object ,we follow a 2 step procedure: 1.We got to the super class and check whther the method is present or not.\nif(present) Goto to step 2 else COMPILE ERROR 2.Come to the sub class and check wther the method is overrided or not.\nif(overrided) Call the sub-class version else Call the super -class version. Eg:\nclass A{ void m1(){ System.out.println(\u0026#34;A\u0026#34;); }} class B extends A{ void m1(){ System.out.println(\u0026#34;B\u0026#34;); }} class App{ public static void main(String[]args){ A a=new B(); a.m1(); //Follow the rule B=new B(); b.m1(); //Normal sub class object method call }} OUTPUT: B B So that’s all for polymorphism in java.\nHappy Learning :)\n","permalink":"https://codeklutz.com/posts/polymorphism-in-java/","summary":"Just revisiting and explaining myself Polymorphism concept here through a blog post. The words Polymorphism means multiple forms.\nIn Java ,Polymorphism means multiple forms of an object. We shall divide this article into 3 sections.\n1.Syntax\n2.Calling a variable polymorphically.\n3.Calling a method polymorphically.\n1.SyntaxPermalink Now in polymorphism in Java, the thumb key rule to remember is\nsuper = subPermalink Meaning the variable reference (LHS) must always be a super class reference and the object initialization(RHS) must a sub class.","title":"Polymorphism in Java"},{"content":"Constructors are used every time to initialize instance variables. There are some additional rules associated with constructors that are often asked in interviews.Hence revising those here through a blog post.\nA constructor is used to initialize instance variables When an object of an class is created,JVM goes to the class and searches for that matching constructor.If Constructor is NOT PRESENT it gives a compile error. By default every class has a constructor called default no argument constructor. class A{ A(){ //default no arg constructor }} A programmer can have multiple constructors in a class provided their signatures are different this is called constructor overloading. class A{ A(){ //some code } A(int x){ //some code } A(float x){ //some code } A(float x,int y){ //some code } A(int x,float y){ } A(int z){}//THIS WILL GIVE COMPILE ERROR SInce its already defined on top. } A a=new A(); new A();//goes to first matching constructor JVM always calls the matching constructor from the class.HOWEVER,a programmer can call other constructors of this class by using the the this() method. class A{ A(){ System.out.println(\u0026#34;A\u0026#34;); //I A(int x){ this(); //this will go to constructor A(); System.out.println(\u0026#34;AA\u0026#34;); //II } } class App{ public static void main(String[]args){ new A(5); }} OUTPUT: A AA If a programmer desires it can call the constructor of the super class as well from its own constructor using the super() method. class A{ A(){ System.out.println(\u0026#34;A\u0026#34;); //I } } class B extends A{ B(){ super(); //this is called implicitly refer next point also System.out.println(\u0026#34;B\u0026#34;); }} class HelloWorld { public static void main(String[] args) { new B(); } } OUTPUT: A B Whenever a programmer creates a constructor ,JVM writes super() in every constructor implicitly as its first line. Note:If a class does not extend any class it by default extends the Object class. Do Try this code in your ide to see it for yourself\nclass A{ A(){ //super will be called implicitly at the first line of this constructor and here since it does not extend any class it will extend the Object class System.out.println(\u0026#34;A\u0026#34;); //I } A(int x){ //super will be called implicitly at the first line of this constructor System.out.println(\u0026#34;AA\u0026#34;); }} class HelloWorld { public static void main(String[] args) { new A(5); } } OUTPUT: A AA That’s all for constructors in Java.\nHappy Learning :)\n","permalink":"https://codeklutz.com/posts/how-constructors-work-in-java/","summary":"Constructors are used every time to initialize instance variables. There are some additional rules associated with constructors that are often asked in interviews.Hence revising those here through a blog post.\nA constructor is used to initialize instance variables When an object of an class is created,JVM goes to the class and searches for that matching constructor.If Constructor is NOT PRESENT it gives a compile error. By default every class has a constructor called default no argument constructor.","title":"How constructors work in Java"},{"content":"The Good parts are made by me,\nThe Bad parts are made by me.\n","permalink":"https://codeklutz.com/layouts/partials/extend_footer/","summary":"The Good parts are made by me,\nThe Bad parts are made by me.","title":""},{"content":"Presenting my first talk at GitTogether Mumbai\n","permalink":"https://codeklutz.com/talk/","summary":"Presenting my first talk at GitTogether Mumbai","title":""},{"content":" Hi, I’m Shweta Kadam 👋 Backend-first engineer with ~5 years of experience building and scaling fintech systems.\nMost at home with Java + Spring, but I also ship reliable services on AWS, Docker, Kubernetes.\nMain Skills: Most proficient in Java, Spring, Angular and dabble a bit with Kubernetes.\nExperience: 5 years\nProgramming Languages: Java\nDatabases: MySQL\nInfrastructure: Docker, Kubernetes, CI/CD (GitHub Actions, Jenkins)\nCloud: Amazon Web Services\nOperating Systems: macOS, Linux (Ubuntu), Windows 10\nOther: Command Line, Git, Agile, Scrum, Atlassian Suite (Jira, Confluence, Bitbucket)\nEducation: Engineering degree in Computer Branch from Mumbai University.\nSkills: Technical: I fix more things than I break and create new things that don\u0026rsquo;t break as often. Social: Great communication | pleasant to work with | works great by myself \u0026amp; in a team.\nCheck out my work Code on my GitHub I love Coding - Music - Anime - Writing.\nLinks GitHub LinkedIn RSS Feed\nContact Me hello@shweta.io or LinkedIn\n","permalink":"https://codeklutz.com/about/","summary":"about","title":"About"}]