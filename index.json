[{"content":"Learning SSL itself is not a straight forward concept as it seems but even confirming if a particular url is on 2 way ssl requires some effort. I face some trouble with ssl in the past so just a blog post describing my pain.\n1 way ssl Client -\u0026gt; Server When a client (browser) hits the url and it gives success for example Google.com.It is usually on 1 way ssl. In this case, only the client authenticates the server.\nIf an API call(curl/postman) succeeds without passing any certificate, it\u0026rsquo;s on 1-way ssl.\nSo the situations might look like :\nIf one makes a curl call and it succeeds without passing any client cert with flags such as \u0026ndash;key and \u0026ndash;cert. then it is on 1-way SSL. If the Postman API call succeeds without passing any client certificate in Postman (Preferences -\u0026gt; Certificates tab -\u0026gt; Client certificate tab) with Enable SSL certificate verification toggled on, it is on 1-way SSL. The curl output of 1 way SSL looks like this.(Data has been changed and added fake data for DEMO Purposes):\n‚ùØ curl -v https://exampleOf1wayySSL.com Trying 82.133.101.34... * TCP_NODELAY set * Connected to exampleOf1wayySSL.com (10.10.10.10.10) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * successfully set certificate verify locations: * CAfile: /etc/ssl/cert.pem CApath: none * TLSv1.2 (OUT), TLS handshake, Client hello (1): * TLSv1.2 (IN), TLS handshake, Server hello (2): * TLSv1.2 (IN), TLS handshake, Certificate (11): * TLSv1.2 (IN), TLS handshake, Server key exchange (12): * TLSv1.2 (IN), TLS handshake, Server finished (14): * TLSv1.2 (OUT), TLS handshake, Client key exchange (16): * TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1): * TLSv1.2 (OUT), TLS handshake, Finished (20): * TLSv1.2 (IN), TLS change cipher, Change cipher spec (1): * TLSv1.2 (IN), TLS handshake, Finished (20): * SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256 * ALPN, server did not agree to a protocol * Server certificate: * subject: C=RANDOM; L=RANDOM; O=EXAMPLE. OHG; CN=*exampleof1wayssl * start date: Feb 11 00:00:00 2012 GMT * expire date: Mar 8 23:59:59 2024 GMT * subjectAltName: host \u0026#34;exampleOf1wayssl.com\u0026#34; matched cert\u0026#39;s \u0026#34;*.exampleof1wayssl\u0026#34; * issuer: C=US; O=DigiCert Inc; CN=DigiCert TLS RSA SHA256 2020 CA1 * SSL certificate verify ok. \u0026gt; GET / HTTP/1.1 \u0026gt; Host: exampleOf1wayySSL.com \u0026gt; User-Agent: curl/7.64.1 \u0026gt; Accept: / \u0026gt; In this example as you can see only the client asked for the certificate with line TLSv1.2 (IN), TLS handshake, Certificate (11):\n2 way SSL (Client \u0026lt;-\u0026gt; Server) In 2 way ssl Both client and server ask for the certificate during SSL validation.So while validating the scenarios should look like this:\ncurl fails without passing any client cert. When one makes a CURL call to API/Endpoint (curl -v -k \u0026lt;baseURL/endpoint\u0026gt;) without passing flags such as --key and --cert, the curl call should fail with a handshake failure. From the response, make a note of the line with Request CERT (example below) So if a curl call succeeds without passing any flags, then it\u0026rsquo;s not on 2 way SSL.\nFor a 2-way SSL, the server would ask for a client certificate. (TLSv1.2 (IN), TLS handshake,¬†Request CERT (13) in this case, example in code block below\nIn this example, we didn\u0026rsquo;t pass any certificate in curl with flags such as --key and --cert, and hence it resulted in handshake failure below * error:1401E410:SSL routines:CONNECT_CR_FINISHED:sslv3 alert handshake failure\ncurl -v -k https://2WaySSLExample.com * Trying 82.133.101.34.. * TCP_NODELAY set * Connected to 2WaySSLExample.com (82.133.101.34) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * successfully set certificate verify locations: * CAfile: /etc/ssl/cert.pem CApath: none * TLSv1.2 (OUT), TLS handshake, Client hello (1): * TLSv1.2 (IN), TLS handshake, Server hello (2): * TLSv1.2 (IN), TLS handshake, Certificate (11): * TLSv1.2 (IN), TLS handshake, Request CERT (13): * TLSv1.2 (IN), TLS handshake, Server finished (14): * TLSv1.2 (OUT), TLS handshake, Certificate (11): * TLSv1.2 (OUT), TLS handshake, Client key exchange (16): * TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1): * TLSv1.2 (OUT), TLS handshake, Finished (20): * TLSv1.2 (IN), TLS alert, handshake failure (552): * error:1401E410:SSL routines:CONNECT_CR_FINISHED:sslv3 alert handshake failure * Closing connection 0 The server would ask for a client certificate in this case\nIn some unusual cases; it\u0026rsquo;s possible a server doesn\u0026rsquo;t directly ask for it but the client needs to send it or gets rejected. The standard is: the server asks for it.\ncurl fails without passing any client cert(NSS is used) Similar to /etc/ssl/cert.pem, NSS(Network Security Services) as a trusted CA certificate location. Another example of trusted CA cert location is jdk cacerts for java applications.\nAll three /etc/ssl/cert.pem, NSS, and JDK¬†cacerts are used to store trusted root certificates but differ in their implementation and usage. So while using curl output of ssl handshake failure might look like this :\ncurl -v https://2WaySSLExampleUsingNSS.com * About to connect() to 2WaySSLExampleUsingNSS.com port 443 (#0) * Trying 82.133.101.34..... * Connected to 2WaySSLExampleUsingNSS.com (82.133.101.34) port 443 (#0) * Initializing NSS with certpath: sql:/etc/pki/nssdb * CAfile: /etc/pki/tls/certs/ca-bundle.crt CApath: none * NSS: client certificate not found (nickname not specified) * NSS error -12227 (SSL_ERROR_HANDSHAKE_FAILURE_ALERT) * SSL peer was unable to negotiate an acceptable set of security parameters. * Closing connection 0 curl: (35) NSS: client certificate not found (nickname not specified Make note of curl: (35) NSS: client certificate not found (nickname not specified) where we are not passing any client cert or key and get the expected error. curl -v \u0026lt;url\u0026gt; \u0026ndash;cacert ca.crt \u0026ndash;key private.key¬†\u0026ndash;cert client.cer\nHappy curl case where we pass the client cert and key The happy case of a curl call where we pass client cert and key would look like this curl -v \u0026lt;url\u0026gt; --cacert ca.crt --key private.key¬†--cert client.cer\ncurl -v https://HappyCurlCase.com --key ./myKey.key --cert ./myCert-cert.crt * About to connect() toHappyCurlCase.com port 443 (#0) * Trying 82.133.101.34..... * Connected to HappyCurlCase.com ( 82.133.101.34) port 443 (#0) * Initializing NSS with certpath: sql:/etc/pki/nssdb * CAfile: /etc/pki/tls/certs/ca-bundle.crt CApath: none * NSS: client certificate from file * subject: E=\u0026lt;SOME_ISSUER\u0026gt; ,CN=\u0026lt;SOME_CN\u0026gt;,OU=\u0026lt;SOME_OU\u0026gt;\u0026gt;,O=\u0026lt;SOME_RANDOM_VALUE\u0026gt;_ * start date: Mar 24 13:31:56 2026 GMT * expire date: Mar 31 23:59:59 2029 GMT * common name: \u0026lt;some_common_name\u0026gt; issuer:E=\u0026lt;SOME_ISSUER\u0026gt; ,CN=\u0026lt;SOME_CN\u0026gt;,OU=\u0026lt;SOME_OU\u0026gt;\u0026gt;,O=\u0026lt;SOME_RANDOM_VALUE\u0026gt;_ * SSL connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 * Server certificate: * subject: CN=\u0026lt;some_common_name\u0026gt;,O=\u0026lt;some_organization\u0026gt; * start date: Mar 24 13:31:56 2026 GMT * expire date: Mar 31 23:59:59 2029 GMT * common name: \u0026lt;some_common_name\u0026gt; * issuer: CN=DigiCert Global G1 TLS RSA SHA256 2020 CA1,O=DigiCert Inc,C=US \u0026gt; GET / HTTP/1.1 \u0026gt; User-Agent: curl/7.29.0 \u0026gt; Host: HappyCurlCase.com \u0026gt; Accept: / \u0026gt; \u0026lt; HTTP/1.1 404 Not Found \u0026lt; Content-Type: application/json; charset=utf-8 \u0026lt; Date: Tue, 28 Mar 2023 14:36:34 GMT \u0026lt; Connection: keep-alive \u0026lt; Keep-Alive: timeout=5 \u0026lt; Content-Length: 41 \u0026lt; Verifying if Client key is being used in authentication Many times I have faced a scenario where the other party claims that they configured 2 way ssl correctly but actually the key is never used in the ssl authentication process.So there are way to figure if its actually being used by looking for certain outputs.\nUsing openssl command. When trying to verify via openssl command, openssl s_client -servername someExampleDomain -connect someExampleDomain.com:443 ,for a happy case look for Acceptable client certificate CA names The client (browser or curl) must select the correct client certificate from its keystore location based on the rules below. If this doesn\u0026rsquo;t exist then it won\u0026rsquo;t use the client key. And this client key is stored any location your application or somewhere else.\nAcceptable client certificate CA names C = US, O = Example CA, CN = Example Root CA C = US, O = Example CA, CN = Example Intermediate CA openssl s_client -servername someExampleDomain -connect someExampleDomain.com:443 CONNECTED(00000003) depth=2 C = US, O = Example CA, CN = Example Root CA verify return:1 depth=1 C = US, O = Example CA, CN = Example Intermediate CA verify return:1 depth=0 C = US, ST = California, L = San Francisco, O = Example Inc., CN = someExampleDomain.com verify return:1 --- Certificate chain 0 s: C = US, ST = California, L = San Francisco, O = Example Inc., CN = someExampleDomain.com i: C = US, O = Example CA, CN = Example Intermediate CA 1 s: C = US, O = Example CA, CN = Example Intermediate CA i: C = US, O = Example CA, CN = Example Root CA --- Server certificate -----BEGIN CERTIFICATE----- MIIFzDCCBLSgAwIBAgIRAKBYEa+5G0pMFMWcTPWdDb8wDQYJKoZIhvcNAQELBQAw gYsxCzAJBgNVBAYTAlVTMRYwFAYDVQQIDA1DYWxpZm9ybmlhMRYwFAYDVQQHDA1T \u0026lt;...Random Certificate content...\u0026gt; fUeyIkVJ17E4wj1jv7dwD2NW9/Jg2U4vA5s2nRO2fX0CXU1IK1WueBq/AVhUo+3E cGxfJyzCvujpBT9tpH4twQ== -----END CERTIFICATE----- subject=C = US, ST = California, L = San Francisco, O = Example Inc., CN = someExampleDomain.com issuer=C = US, O = Example CA, CN = Example Intermediate CA --- Acceptable client certificate CA names C = US, O = Example CA, CN = Example Root CA C = US, O = Example CA, CN = Example Intermediate CA ---Server Temp Key: ECDH, P-256, 256 bits --- SSL handshake has read 2498 bytes and written 304 bytes Verification: OK --- New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384 Server public key is 2048 bit Secure Renegotiation IS supported Compression: NONE Expansion: NONE No ALPN negotiated Early data was not sent Verify return code: 0 (ok) --- If you don\u0026rsquo;t see your CA(client\u0026rsquo;s CA) mentioned in the above Acceptable client certificate CA names section then that means the URL is not using the client key for authentication and there might have been misconfiguration. Another example of a client key not being used during SSL handshake is indicated by No client certificate CA names sent Example output :\n$ openssl s_client -servername someExampleDomain -connect someExampleDomain.com:443 CONNECTED(00000003) depth=2 C = US, O = Example CA, CN = Example Root CA verify return:1 depth=1 C = US, O = Example CA, CN = Example Intermediate CA verify return:1 depth=0 C = US, ST = California, L = San Francisco, O = Example Inc., CN = someExampleDomain.com verify return:1 --- Certificate chain 0 s: C = US, ST = California, L = San Francisco, O = Example Inc., CN = someExampleDomain.com i: C = US, O = Example CA, CN = Example Intermediate CA 1 s: C = US, O = Example CA, CN = Example Intermediate CA i: C = US, O = Example CA, CN = Example Root CA --- Server certificate -----BEGIN CERTIFICATE----- MIIFzDCCBLSgAwIBAgIRAKBYEa+5G0pMFMWcTPWdDb8wDQYJKoZIhvcNAQELBQAw gYsxCzAJBgNVBAYTAlVTMRYwFAYDVQQIDA1DYWxpZm9ybmlhMRYwFAYDVQQHDA1T YW4gRnJhbmNpc2NvMRMwEQYDVQQKDApFeGFtcGxlIENBMRIwEAYDVQQDDAlleGFt cGxlLmNvbTAeFw0yMTA5MTUwMzQzMjNaFw0yMTA5MTYwMzQzMjNaMEwxCzAJBgNV BAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9ybmlhMRMwEQYDVQQHEwpTYW4gRnJhbmNp c2NvMRMwEQYDVQQKEwpFeGFtcGxlIEluYy4xEjAQBgNVBAMTCXNvbWVFeGFtcGxl LmNvbTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBAJDEi5WSU95UTq0A LanrVthBLYAmgU7X5D3HFF+T8Ghz9MbYa1Mw/eXxiC0vBo2eM1YyTS2JDLum56KU E3Moc5Vcm8yBtBgU2amKazSxS7VzQsEj5+lzp6f9yyzm32HeMeiTY4W31ehobLkj QYb6ChhQqWd0qXnoy9UoT2Cn1lRfIAYoJy1l2a/8Vt0Zk44MTKm4EGkmzRFm7JCu NyFNU5iR8p9yUmmupzDMDlum3VwsbtmYmLwib9EBK0rAF9DkR9QJcYeeV4bZiQv1 wjJthoPQ1sFIZsXdJCTUUK9l25H4xXHmWmpNfn9JlD5vGe \u0026lt;...Certificate content...\u0026gt; fUeyIkVJ17E4wj1jv7dwD2NW9/Jg2U4vA5s2nRO2fX0CXU1IK1WueBq/AVhUo+3E cGxfJyzCvujpBT9tpH4twQ== -----END CERTIFICATE----- subject=C = US, ST = California, L = San Francisco, O = Example Inc., CN = someExampleDomain.com issuer=C = US, O = Example CA, CN = Example Intermediate CA --- No client certificate CA names sent Server Temp Key: ECDH, P-256, 256 bits --- SSL handshake has read 2498 bytes and written 304 bytes Verification: OK --- New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384 Server public key is 2048 bit Secure Renegotiation IS supported Compression: NONE Expansion: NONE No ALPN negotiated Early data was not sent Verify return code: 0 (ok) Using Java Flags in application logs One can also verify the same in Java by checking your application logs and enabling a flag -Djavax.net.debug=ssl or in some cases -Djavax.net.debug=all which gives more verbose logs. If the client key is not being during ssl handshake, the error log might look like this:\n*** ServerHelloDone [read] MD5 and SHA1 hashes: len = 4 0000: 0Z 00 00 00 .... Warning: no suitable certificate found - continuing without client authentication *** Certificate chain \u0026lt;Empty\u0026gt; During a happy case you should see the chain below ServerHelloDone\n*** ServerHelloDone [read] MD5 and SHA1 hashes: len = 4 0000: 0Z 00 00 00 matching alias: \u0026lt;some_random_alias\u0026gt; *** Certificate chain chain [0] = [ [ These were some of the tricks I used to verify.In future blog posts, I will include how to test using Postman too. Happy Learning!\n","permalink":"https://codeklutz.com/posts/today-i-learnt-how-to-check-if-a-url-is-on-2-way-ssl-or-not/","summary":"Learning SSL itself is not a straight forward concept as it seems but even confirming if a particular url is on 2 way ssl requires some effort. I face some trouble with ssl in the past so just a blog post describing my pain.\n1 way ssl Client -\u0026gt; Server When a client (browser) hits the url and it gives success for example Google.com.It is usually on 1 way ssl. In this case, only the client authenticates the server.","title":"Today I learnt : How to check if a url is on 2 way SSL or not ?"},{"content":"Often while debugging when are browsing code getting familiar with the code base and the context it is trying to say.We notice and observe several things which may need refactoring such as dependency may be out of date , outdated design pattern, a better way to handle exceptions and adding comments where necessary.The urge to leave the code in a better state than it was\nAnother situation could also be coming across a concept or bug for which you might have got the solution for but not understood it completely or would like to study it further.\nWhile these things are what makes us feel good about ourselves.It is important to not lose sight of the main goal or bug you are trying to solve.\nOne thing I find myself doing these days is focusing on the prioritised issue at hand first.Ask a senior or engineer who has more context and information about the issue at hand. And simultaneously note down the topics which I didn\u0026rsquo;t understand completely in another place (sublime or self slack) for me to refer later and learn once the work storm calms down.\nThis is one way I could to get back to learning new things\u0026hellip;..\n","permalink":"https://codeklutz.com/posts/beware-of-the-side-bug/","summary":"Often while debugging when are browsing code getting familiar with the code base and the context it is trying to say.We notice and observe several things which may need refactoring such as dependency may be out of date , outdated design pattern, a better way to handle exceptions and adding comments where necessary.The urge to leave the code in a better state than it was\nAnother situation could also be coming across a concept or bug for which you might have got the solution for but not understood it completely or would like to study it further.","title":"Beware of the side bug"},{"content":"Recently got an opportunity to work on angular project.With no previous experience in angular, I had some catch up to do in terms of web development.So here is a small blog post.\nWhat is Angular ? Framework to build client side applications.\nWhy would you use Angular? Vanilla JQuery code gets harder to maintain,harder to test.\nAnd like all most of the frameworks Junction, Angular provides:\nAngular gave our applications clean structure. Includes lots of Reusable code Makes the application more testable Also easier to co-relate to learn from Java perspective because of 2 features Dependency Injection Typescript gives our plain JS applications some structure \u0026amp; enables static typing.\n3 Handles Server-side Rendering We don\u0026rsquo;t save the data in client. We save it in server. Example: Data is wiped clean when user creates form.\nFrontend Backend \u0026ndash;\u0026gt; Backend (Presentation logic) Data APIs Business\nLet\u0026rsquo;s get familiar with some terms in Angular first. Below is small comparison to co relate between Java and angular.\nWhat Java Angular Dependency management Maven npm(node package manager ) Build/package Maven webpack Library Repo Maven Central npmjs.org Project Descriptor pom.xml package.json Programming language Java Typescript ,HTML Platform runtime JVM Browser/NodeJS Unit Testing Junit Karma/jasmine Reactive Programming RxJava RxJS Code style checks Sonar eslint Browser End-to-end testing Webdriver Protractor (Layer on top of selenium) Like java has a main file. Similarly in angular, there is a main.ts file which is the starting point of our application.It is present in bootstrapmodule(Appmodule).\nWebpack Angular uses a tool called webpack which is a static module bundler.It takes all our HTML,CSS and JS files and bundles them into a single file which is loaded by the browser. It bundles application source code into convenient chunks, to improve performance and load times. Hot Module replacement Hot Module Replacement (HMR) is a feature of webpack that allows developers to update code changes without the need for a full page reload. When a code change is made, HMR only updates the module that has been modified, which means the application can continue running while the changes are applied.\n","permalink":"https://codeklutz.com/posts/learning-angular-as-a-java-developer/","summary":"Recently got an opportunity to work on angular project.With no previous experience in angular, I had some catch up to do in terms of web development.So here is a small blog post.\nWhat is Angular ? Framework to build client side applications.\nWhy would you use Angular? Vanilla JQuery code gets harder to maintain,harder to test.\nAnd like all most of the frameworks Junction, Angular provides:\nAngular gave our applications clean structure.","title":"Learning Angular as a Java Developer"},{"content":"We have all experienced this often where we are stuck on an issue. We feel we have not earned the right to ask the doubt yet till we reach an imaginary threshold or baseline. The feeling of doing some research before reaching out to someone.\nThen time passes and so does the feeling of shame.The shame of not being able to solve the doubt on my own and yet feeling the hesitation to reach out to a senior.\nThe best resolution no matter how much hesitation or shame is to ASK NOW! It does two things:-\nFilters out your misunderstandings and gives you clarity. Always end up learning something new. Also if the point is in just the idea or analysis stage ,one can validate the effectiveness of an idea faster . How much important or effective an idea is as a solution to a problem or if there are better solutions. ","permalink":"https://codeklutz.com/posts/when-to-ask-for-help-as-a-software-engineer/","summary":"We have all experienced this often where we are stuck on an issue. We feel we have not earned the right to ask the doubt yet till we reach an imaginary threshold or baseline. The feeling of doing some research before reaching out to someone.\nThen time passes and so does the feeling of shame.The shame of not being able to solve the doubt on my own and yet feeling the hesitation to reach out to a senior.","title":"When to ask for help as a Software Engineer?"},{"content":"Today I learnt a few kubectl commands which I used to for debugging a few issues in testing environment at work.\nTo check logs kubectl logs -f pod_name Useful when you need to check logs inside a pod.\nTo get the bin bash inside a pod kubectl --exec --stdin --tty podname --bin/bash This is useful command to check for certain versions or debugging which is done This command was helpful for determining Java versions inside the pod which was used in a particular environment. Anytime you want to run terminal commands such as java --version Or something similar to execute commands which need a bash shell.This is a good approach. Helps to know which dependencies a pod uses.\nScale up and downscale your pod kubectl scale deployment \u0026lt;application-name\u0026gt; --replicas=0 kubectl scale deployment \u0026lt;application-name\u0026gt; --replicas=1 If your company uses a UI to scale up application pods and that UI tests your patience then this is a quick fix(Not recommended in PROD).\nGet description of your pod. kubectl describe services This commands gives general information regarding image IDs. If your company uses Jenkins to make builds and then deploys them uses kubernetes,and if you need a way to verify if Jenkins deployed that particular build.This one helps as you can cross verify that information using attributes such as (sha)\n","permalink":"https://codeklutz.com/posts/today-i-learnt-kubectl-commands-for-debugging/","summary":"Today I learnt a few kubectl commands which I used to for debugging a few issues in testing environment at work.\nTo check logs kubectl logs -f pod_name Useful when you need to check logs inside a pod.\nTo get the bin bash inside a pod kubectl --exec --stdin --tty podname --bin/bash This is useful command to check for certain versions or debugging which is done This command was helpful for determining Java versions inside the pod which was used in a particular environment.","title":"Today I learnt : Kubectl commands for debugging"},{"content":"While I migrating this website, I came across many issues. One such issue was git submodule.So here is a post on it.\nwhat is a git submodule? Git submodule is a way to include another repository in Git as a sub directory in one repository.\nIt allows you to keep another repo(your own repo or someone else) in your repo as a subdirectory It is useful for track that repo\u0026rsquo;s changes and use that project repo as a reference.\ngit submodule add https://github.com/username/repo-name.git It‚Äôs important to note the username of the repo you are adding. Because whose username is present in the repo, the repo belongs to them. So they have ownership of the repo and the changes over it.\nWhat issue I faced ? I use Hugo Papermod theme for this website. I used the git submodule method for installing this theme in my Hugo repo.\ngit submodule https://github.com/adityatelange/hugo-PaperMod.git --depth=1 Instead of\ngit submodule https://github.com/MY-GITHUB-USERNAME/hugo-PaperMod.git --depth=1 What did this lead to? For adding GitHub comments feature, the changes had to be done inside layout/partials/comments.html\nThis file is present in the submodule directory.This lead to the below error:\nwarning: adding embedded git repository: themes/PaperMod hint: You‚Äôve added another git repository inside your current repository. hint: Clones of the outer repository will not contain the contents of hint: the embedded repository and will not know how to obtain it. hint: If you meant to add a submodule, use: hint: hint: git submodule add \u0026lt;url\u0026gt; themes/PaperMod hint: hint: If you added this path by mistake, you can remove it from the hint: index with: hint: hint: git rm --cached themes/PaperMod hint: hint: See ‚Äúgit help submodule‚Äù for more information. I couldn‚Äôt push my changes into repo since I did not have ownership over it\nHow to solve this? There were two ways to solve this:-\nI make a PR of my changes in aditya subdirectory. The owner approves my changes. This is not possible in this case since these changes are custom to my repo and not feature enhancement or bug fix\nI remove all git submodule of Aditya ‚Äôs changes .Fork Aditya papermod theme(so now the forked repo belong to me ) and link the git submodule to my forked repo. I went with the second route.\nBut turns out removing all references of git submodule can be quite annoying.\nEvery time I thought I removed all submodule references using stackoverflow answers I ended up on the same above error. This meant there were still submodule references present.\nFound this useful Github Gist\nDelete the relevant section from the .gitmodules file. Delete the relevant section from the .gitmodules file. In my case entries looked like\n‚îÇ [submodule ‚Äúthemes/PaperMod‚Äù] 2 ‚îÇ path = themes/PaperMod 3 ‚îÇ url = https://github.com/adityatelange/hugo-PaperMod.git Stage the .gitmodules changes git add .gitmodules\nDelete the relevant section from .git/config For me no submodule entries were present.\nRun git rm --cached path_to_submodule (no trailing slash).In my case it was git rm --cached themes/Papermod\nRun rm -rf .git/modules/path_to_submodule (no trailing slash).\nCommit git commit -m ‚ÄúRemoved submodule ‚Äù\nDelete the now untracked submodule files rm -rf path_to_submodule\nThis removed my git submodules entries. And then again created a submodule entry with my usernameAnd that\u0026rsquo;s how the git submodule error was solved. **\n","permalink":"https://codeklutz.com/posts/today-i-learnt-til-git-modules-how-to-effectively-remove-submodules/","summary":"While I migrating this website, I came across many issues. One such issue was git submodule.So here is a post on it.\nwhat is a git submodule? Git submodule is a way to include another repository in Git as a sub directory in one repository.\nIt allows you to keep another repo(your own repo or someone else) in your repo as a subdirectory It is useful for track that repo\u0026rsquo;s changes and use that project repo as a reference.","title":"Today I learnt TIL :GIT Modules \u0026 How to effectively remove submodules"},{"content":"It\u0026rsquo;s been a fruitful and amazing year.And that means documenting my small journey as a blog post.\nWork New friends and mentors I joined my new work place in September 2021 \u0026amp; had the pleasure to meet some amazing developers and colleagues.\nI got the opportunity to learn a lot while on the job, through mentors, environment \u0026amp; infrastructure itself.\nPromoted to Software Engineer 2 The title says all and I am grateful for it. Without such an awesome environment, I wouldn\u0026rsquo;t have faced the challenges, support and mentorship that I did.\nBlogging Migrating my blog from Jekyll to Hugo I regretted not writing more posts in 2019 even though I had my blog setup on Jekyll . It was not the lack of time that bothered me but more of lack of proper process.\nAs atomic habits books rightly said to develop a habit ,the habit must be easier to execute.After shifting to Doom Emacs this year to make documentation, it made sense to shift my blog from Jekyll to Hugo(Incoming blog post stay tuned!).\nWriting my posts in markdown just for my blog was creating the friction in my writing process. Writing all my posts in .org mode helped me reduced that friction and made my process better.\nAlso by introducing small Today I learnt concepts (tils) posts helped me further in being consistent in writing. As I wrote about the the things I learnt while working and didn\u0026rsquo;t need to invest extra time and effort into researching and writing separate posts.\nLessons learnt: Do one thing at a time One of the biggest lessons I have learnt this year is not to take on too many projects at once .To focus on one thing and to do that properly. I have realised doing too many things at once , made me rush to one project haphazardly so I could complete the next one . This is reminder to myself to complete a project to a satisfactory stage and then move on.\nDocument your software process/journey before/while doing it. Documentation about the work I has always felt like a daunting task to me.But not having proper docs has been more painful.\nOne of key lessons, I am still learning is to make the document while working on the project. To treat writing as a part of the development process and not as an afterthought. One way I recently realised how to do this is to write the titles and subtitles about dos .This helps in breaking down a big problem into a small one. Example: Im trying to put in place this strategy for blog writing too.\nBe organised I found my old diary of 2013 (when I was still preparing for JEE mains ). It showed me a reflection of how I used to organize content for my studies so why not for learning while working and for blogging? This is why I made the decision to learn doom Emacs and vim and use org-mode as a part of being organized. There is a steep learning curve in Emacs. I myself have given up many times on Emacs and have come back because of the useful features it provides.\nDone is better than perfect A lesson I learnt the hard way. All the planning and over thinking can do no good if you don\u0026rsquo;t execute the plan. Just start with an initial plan and start executing it. Putting a little thought into the execution can lead to remarkable results.\nWhat\u0026rsquo;s next? Automation of content creation flow Continuing to refine my blog content creation post workflow, I will explore ways to reach out to wider audience. To do this in such a way that it doesn\u0026rsquo;t take much mental effort from my side. And to find a way to reduce my time and effort in the proof reading \u0026amp; editing process.(Any advice or suggestions are welcome!)\nGetting better at note taking and diagram making One of the key goals for 2023 is taking the effort to make quick diagrams. I have understood concepts quicker by looking at diagrams than reading blocks of text . But diagram making tends to be a long time consuming task. I am currently trying out draw.io and excalidraw for this purpose ,still at experimental stage tho.\nTrying out public speaking or podcast of my learning While explaining a concept to a friend or colleague helped in finding out the gaps in my learning. Though I tried to explain a concept to myself while learning, I tend to find it awkward or sometimes lazy to re-iterate to explain the concept back to myself. One of my goals is to get better at speaking and hopefully not bore my little audience.\nAnd that\u0026rsquo;s all for my year end review for 2022 !\n","permalink":"https://codeklutz.com/posts/my-2022-year-review/","summary":"It\u0026rsquo;s been a fruitful and amazing year.And that means documenting my small journey as a blog post.\nWork New friends and mentors I joined my new work place in September 2021 \u0026amp; had the pleasure to meet some amazing developers and colleagues.\nI got the opportunity to learn a lot while on the job, through mentors, environment \u0026amp; infrastructure itself.\nPromoted to Software Engineer 2 The title says all and I am grateful for it.","title":"My 2022 Year Reviewüìì"},{"content":"Today at work once again I had to inspect a json body which was not beautified. Normally I turn to Postman and use the beautify option. But my mac cried and was freezing in instances begging for me to not open more application :( This is where I came across a nifty tool called jq\njq is a lightweight and flexible command-line JSON processor. It is like sed for JSON data. It can used to transform json data into more readableformat. For example :\n‚ùØ echo \u0026#39;{\u0026#34;fullName\u0026#34;: {\u0026#34;firstName\u0026#34;: \u0026#34;Bruce\u0026#34;,\u0026#34;middleName\u0026#34;: \u0026#34;Clark\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Wayne\u0026#34; }}\u0026#39; | jq . { \u0026#34;fullName\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;Bruce\u0026#34;, \u0026#34;middleName\u0026#34;: \u0026#34;Clark\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Wayne\u0026#34; } } Where and why would you use it? There are a few reasons I could think of why I would use jq regularly:\nSimilarly like my situation above, if you want to avoid opening gui apps or online code beautifiers ,this is a great option. Once can prettify a curl output with jq.\nThis is a great option when you pretty json output on the go for example healthcheck urls of your application apis.\ncurl http://example-api-url-you-are-calling.com | jq . curl http://example-api-healthcheck.com/healthcheck | jq . jq is ubiquitous means it is pre-installed in most machines (even cloud vms such as aws and microsoft vms).\nSo next time you want pretty output of a json which is present in an ec2 instance. You dont need to do the manual work of copy and paste and json and figuring it out later.\nAlso I think its pretty secure than the online third party websites developers tend to use to prettify json ,xml while working. Especially when dealing with secret private data which is sometimes pasted on to a random code beautifier website. And pretty handy when you lose internet connection ;) When used in shell scripts , it can save a lot of time and manual effort.\nThis is useful cheat sheet with good example to refer https://lzone.de/cheat-sheet/jq\n","permalink":"https://codeklutz.com/posts/today-i-learnt-til-jq/","summary":"Today at work once again I had to inspect a json body which was not beautified. Normally I turn to Postman and use the beautify option. But my mac cried and was freezing in instances begging for me to not open more application :( This is where I came across a nifty tool called jq\njq is a lightweight and flexible command-line JSON processor. It is like sed for JSON data.","title":"Today I learnt TIL: jq"},{"content":"Today while testing a soap API at work, I came across this HTTP error code called HTTP/1.1 422 Unprocessable Entity . According to MDN Web docs, it means the following :\nThe HyperText Transfer Protocol (HTTP) 422 Unprocessable Entity response status code indicates that the server understands the content type of the request entity, and the syntax of the request entity is correct, but it was unable to process the contained instructions.\nIt means that the syntax of the request is correct and well-formed but it has semantic, logical errors. Meaning the soap body xml format will be correct but the issue arises because of the content inside the XML tags*. In this case, it could be the following:\nWrong character within the code. The server doesn‚Äôt understand the content within a particular XML tag. Or it refuses to process any other content inside the tag other than a fixed decided value). Difference between 422,404 and 415 Error codes .Permalink According to RFC,\nThe 422 (Unprocessable Entity) status code means the server understands the content type of the request entity (hence a 415(Unsupported Media Type) status code is inappropriate), and the syntax of the request entity is correct (thus a 400 (Bad Request) status code is inappropriate) but was unable to process the contained instructions. For example, this error condition may occur if an XML request body contains well-formed (i.e., syntactically correct), but semantically erroneous, XML instructions.\nIn testing a soap API, the content type of the request body was correct. I checked for Content-Type header while testing) ‚Äì Hence 415(Unsupported Media Type) was not valid. For soap,it was Content-Type: text/xml; charset=UTF-8. And the syntax of the request body was also correct‚Äì Hence 404(Bad request) was not valid.\nThe error occurred due to an incorrect value in the XML tag in my case. Value should have been \u0026lt;ns8:exampleTag\u0026gt;123\u0026lt;/ns8:exampleTag\u0026gt; instead of \u0026lt;ns8:exampleTag\u0026gt;456\u0026lt;/ns8:exampleTag\u0026gt;\n","permalink":"https://codeklutz.com/posts/today-i-learnt422-http-error-code/","summary":"Today while testing a soap API at work, I came across this HTTP error code called HTTP/1.1 422 Unprocessable Entity . According to MDN Web docs, it means the following :\nThe HyperText Transfer Protocol (HTTP) 422 Unprocessable Entity response status code indicates that the server understands the content type of the request entity, and the syntax of the request entity is correct, but it was unable to process the contained instructions.","title":"Today I learnt:422 HTTP Error code"},{"content":"Today at work once again I had to inspect a json body which was not beautified. Normally I turn to Postman and use the beautify option. But my mac cried and was freezing in instances begging for me to not open more application :( This is where I came across a nifty tool called jq\njq is a lightweight and flexible command-line JSON processor. It is like sed for JSON data. It can used to transform json data into more readableformat. For example :\n‚ùØ echo \u0026#39;{\u0026#34;fullName\u0026#34;: {\u0026#34;firstName\u0026#34;: \u0026#34;Bruce\u0026#34;,\u0026#34;middleName\u0026#34;: \u0026#34;Clark\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Wayne\u0026#34; }}\u0026#39; | jq . { \u0026#34;fullName\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;Bruce\u0026#34;, \u0026#34;middleName\u0026#34;: \u0026#34;Clark\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Wayne\u0026#34; } } Where and why would you use it? There are a few reasons I could think of why I would use jq regularly:\nSimilarly like my situation above, if you want to avoid opening gui apps or online code beautifiers ,this is a great option. Once can prettify a curl output with jq.\nThis is a great option when you pretty json output on the go for example healthcheck urls of your application apis.\ncurl http://example-api-url-you-are-calling.com | jq . curl http://example-api-healthcheck.com/healthcheck | jq . jq is ubiquitous means it is pre-installed in most machines (even cloud vms such as aws and microsoft vms).\nSo next time you want pretty output of a json which is present in an ec2 instance. You dont need to do the manual work of copy and paste and json and figuring it out later.\nAlso I think its pretty secure than the online third party websites developers tend to use to prettify json ,xml while working. Especially when dealing with secret private data which is sometimes pasted on to a random code beautifier website. And pretty handy when you lose internet connection ;) When used in shell scripts , it can save a lot of time and manual effort.\nThis is useful cheat sheet with good example to refer https://lzone.de/cheat-sheet/jq\n","permalink":"https://codeklutz.com/posts/til-jq/","summary":"Today at work once again I had to inspect a json body which was not beautified. Normally I turn to Postman and use the beautify option. But my mac cried and was freezing in instances begging for me to not open more application :( This is where I came across a nifty tool called jq\njq is a lightweight and flexible command-line JSON processor. It is like sed for JSON data.","title":"Today I learnt (TIL): jq"},{"content":"I came across a fascinating Java talk on youtube by Devoxx 2022 Hanno Embregts. This article is about a few java snippets I encountered. The purpose of today‚Äôs TIL is to have a list of interesting things we could do in Java and not deep dive into each concept.\nToday‚Äôs TIL : Crazy things to do with Java 11+\nInitializing Array and var keywordPermalink Having the var keyword in a statically typed language such as Java was fascinating in itself(an article on this in the future :). But we never thought we would use it to initialize such as\nvar element =new int[2]; //WORKS var [] element=new int[2]; // COMPILE ERROR :error: \u0026#39;var\u0026#39; is not allowed as an element type of an array Since var is a generic element type, giving it array [] provides an error since rather than being generic we are giving it an array type. C style ArrayPermalink What is a c style array? Java supports providing [] before and after the variable name in an array\nint []arr=new int[2]; int arr1[]=new int[2]; In C style array, we provide [] after the variable name that is ~int arr1[].\nSo in Java, suppose we have the following code:\nint arr1[],arr2; arr1=new int[1]; arr2=new int[1]; //COMPILE ERROR : error: incompatible types: int[] cannot be converted to int The above code will result in COMPILE ERROR for arr2 since arr2 is not an array but a primitive int variable. But if we want to want both arr1 and arr12 as array type we need to change the declaration to\nint [] arr1,arr2; //Notice how [] are arr1=new int[1]; arr2=new int[1]; Arrays.asList and Primitives Let‚Äôs look at the following example :\nString [] strArr={\u0026#34;one\u0026#34;,\u0026#34;two\u0026#34;,\u0026#34;three\u0026#34;}; var stringList= Arrays.asList(strArr); int [] intArray = {1,2,3}; var intList = Arrays.asList(intArray); System.out.println(stringList.contains(\u0026#34;one\u0026#34;)+\u0026#34; \u0026#34;); System.out.print(intList.contains(1)); Output: true false Signature of Arrays.asList is var-args or List of T‚Äôs.\npublic static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; asList(T... a) T is of generic type so that means it needs to reference a Type such as Integer,Float and not reference Array of Ints\nBut next question is Can they boxed ? (Autoboxing: Converting primitive to Class Type example : int -\u0026gt; Integer) Answer is no Array of ints -\u0026gt; Cannot be boxed -\u0026gt; Array of Integer\nDon‚Äôt use Arrays.asList on primitives\nNo structural changes allowed in ArrayPermalink String [] ints ={\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;,null}; List\u0026lt;String\u0026gt; strings= Arrays.asList(ints); strings.removeIf(Objects :: isNull); System.out.println(strings.size()); Output: Exception in thread ‚Äúmain‚Äù java.lang.UnsupportedOperationException: remove at java.base/java.util.Iterator.remove(Iterator.java:102) Because the array does not allow any structural changes to it\nA Unique way to remove null values from Map Map\u0026lt;Integer,String\u0026gt; map=new HashMap(); map.put(4,null); //currently map has key:4 value: null System.out.println(map.getOrDefault(4,\u0026#34;four\u0026#34;)); map.putIfAbsent(4,\u0026#34;four\u0026#34;); //key key:4 value:four System.out.println(map.get(4)); Output: null,four ##\nvar numbers = List.of(-1,0,1); Map\u0026lt;Integer,List\u0026lt;Integer\u0026gt;\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); numbers.forEach(number-\u0026gt; map.putIfAbsent(number,new ArrayList\u0026lt;\u0026gt;()) .add(number)); System.out.println(map.get(0)); Output: NullPointerException: Exception in thread ‚Äúmain‚Äù java.lang.NullPointerException at HelloWorld.lambda$main$0(HelloWorld.java:33) Because map.putIfAbsent returns null if no value is present\n","permalink":"https://codeklutz.com/posts/today-i-learnt-interesting-things-in-java-11/","summary":"I came across a fascinating Java talk on youtube by Devoxx 2022 Hanno Embregts. This article is about a few java snippets I encountered. The purpose of today‚Äôs TIL is to have a list of interesting things we could do in Java and not deep dive into each concept.\nToday‚Äôs TIL : Crazy things to do with Java 11+\nInitializing Array and var keywordPermalink Having the var keyword in a statically typed language such as Java was fascinating in itself(an article on this in the future :).","title":"Today I learnt: Interesting Things in Java 11"},{"content":"Upon stumbling upon this motivating HN post by Simon Willison I have been inspired to start a Today I learnt(TIL) series of my own. This seems like a doable promising idea where I do not have the self-imposed pressure of researching for a blog idea and making a seperate time to write that specific post. Wrting this TIL flows naturally in day-to-day work flow where I could just say ‚ÄúHey I just learnt about this XYZ ,I should write about it‚Äù.\nStarting with Today‚Äôs TIL : Database Version Control\nWhat it is : A practice or form of maintining and tracking every change made to database schema, just like git version control(But this is specifically for Database). It acts like a single source of truth (like a git code repository)\nThis concept solves a lot of problems we face as developers such as :\nAs a developer,One must have faced a situation where to solve a particular problem statement or feature , you need to do database changes,however for those changes to reflect application needs to be restarted or you might have database and application code changes, an organization already has some processes defined for deployment. In development phase, one usually runs the db changes or sql queries in local generally via a sql client application.For example,Update some existing db property.\nBut for that same change to be reflected in production db, CICD processes are define fdd for deployment or a seperate team might be responsible for deployment altogether.Hence we cant expect a seperate db team to always be in sync with deployment team or that particular CICD process. Hence, DB schema changes should be deployed as a part of application code changes.\nThis is where database version control comes in handy where :\nYou need traceability and a commit history of db schema changes done before. Protect prodcution database tables from unwanted or uncontrolled changes Help in communication between teams regarding data(where a member can look at the query and provide feedback as a part of Pull request) Applications such as liquidbase,flyway scripts come in handy Speaking of liquibase which works on changelog concept where you have\nA Changelog file which inside has -\u0026gt; ChangeSet (which are used to define Db changes)- \u0026gt; Which can include SQL Queries and Rollback queries if the changes dont work in that specific environment.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;databaseChangeLog xmlns=\u0026#34;http://www.liquibase.org/xml/ns/dbchangelog\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:ext=\u0026#34;http://www.liquibase.org/xml/ns/dbchangelog-ext\u0026#34; xmlns:pro=\u0026#34;http://www.liquibase.org/xml/ns/pro\u0026#34; xsi:schemaLocation=\u0026#34;http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-latest.xsd http://www.liquibase.org/xml/ns/dbchangelog-ext http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-ext.xsd http://www.liquibase.org/xml/ns/pro http://www.liquibase.org/xml/ns/pro/liquibase-pro-latest.xsd\u0026#34;\u0026gt; \u0026lt;changeSet id=\u0026#34;1\u0026#34; author=\u0026#34;XYZ\u0026#34;\u0026gt; \u0026lt;comment\u0026gt; \u0026lt;/comment\u0026gt; \u0026lt;sql\u0026gt; INSERT INTO Exampledb.exampletable(\u0026#39;id\u0026#39;,\u0026#39;name,\u0026#39;serial\u0026#39;) VALUES(\u0026#34;1\u0026#34;,\u0026#34;test\u0026#34;,\u0026#34;serial\u0026#34;); \u0026lt;/sql\u0026gt; \u0026lt;rollback\u0026gt; DELETE FROM Exampledb.exampletable where id=\u0026#34;1\u0026#34;; \u0026lt;/rollback\u0026gt; \u0026lt;/databaseChangeLog\u0026gt; This changelog file needs to be included in a master changelog file which consists a list of all change log files (Similar to how a git commit history consists of all commit ids)\n","permalink":"https://codeklutz.com/posts/today-i-learnt-database-version-control/","summary":"Upon stumbling upon this motivating HN post by Simon Willison I have been inspired to start a Today I learnt(TIL) series of my own. This seems like a doable promising idea where I do not have the self-imposed pressure of researching for a blog idea and making a seperate time to write that specific post. Wrting this TIL flows naturally in day-to-day work flow where I could just say ‚ÄúHey I just learnt about this XYZ ,I should write about it‚Äù.","title":"Today I learnt: Database Version Control"},{"content":"After a long series of procrastination and getting the hit of motivation from reading Atomic Habits(great book which I recommend others) ,I‚Äôm finally learning kubernetes basics.As a motivator to get better at writing and publish more posts as well as learn kubernetes.I have decided to publish 1 article every Sunday.I would like to post 2 posts per week but I want to start small and consistent. Once again I‚Äôm treating my blog as a journal to showcase how much I actually understand kubernetes.Also its quite handy to have my own notes on a site. So here is a blog post on kubernetes basics part 1.This will be a multi part series. Before we begin some pre requisites which one needs to know :-\nPre requisite You should be already familiar and comfortable with the concept of containers and container run-time such as docker as kubernetes is for managing different containers and their deployment at a large scale.Another point which is not mandatory but good to know would be basic docker commands like docker run etc.\nWhat is kubernetes? Kubernetes is an open-source technology that is used for container orchestration. And what is container orchestration exactly? It is the process of continuous deployment ,scaling and management of containers.\nLets first look at the kubernetes architecture and the individual components in it.\nNode: A Node is either a physical or virtual machine on wihc kubernetes is installed. A node is like a worker machine on which containers (having our application) will be running by Kubernetes.And like any other machine ,nodes can crash for a number of reasons ;) .So once the node crashes the application will be go down as well. So tackle this we need multiple nodes rather than 1 node.\nAnd mulitple nodes come together to form a group known as the cluster.So even if one node inside the cluster fails,we have our application accessible and running from the other nodes.Plus it helps in sharing load!\n* Master Node : So now we have our cluster running on a group of nodes which are running our containerised apps.But who is responsible to manage this cluster:?Also when a node goes down how to direct the traffic of the failed node to other working nodes?Also who stores the information about these worker nodes stored? and How are the nodes monitored?\nThe master node!\nThe master node is another machine with kubernetes installed in it and it watches over the nodes and does the actusl orchestration of the worker nodes.\nNote that a cluster can have multiple master nodes depending on the size of the cluster.\nbecause at the end of the day , a master node is a machine (which can crash) and for high availability we need to avoid that.\nOther components: When you install kubernetes in your system,you are actually installing the follwing components:\nAn Kube api server (Master) An etcd service (Master) -A kubelet service (Worker)\nController (Master) Scheduler (Master) Container Runtime Kube API server: Kubeapi server acts as a frontend for kubernetes.The users,commandline tools,managment devices all interact with the cluster via the Kube API server.\netcd etcd is a distributed key value store used to store data about how to manage the cluster.It is also resp0onsible to implement logs within the cluster to ensure there is no conflict between mulitple masters.\nNote that your application data is not stored in etcd only logs and information about the cluster.\nScheduler Scheduler is responsible is distributing containers across multiple nodes.It looks for newly created containers and assigns them to nodes.\nControllers Controllers are the brain behind the orchestration. They are responsible for notcining and responding nodes,containers or endpoint goes down.The controller takes decsions to bring up new nodes in this case.\nContainer Runtime The container runtime is the underying software that runs the containers.Most of the times,its docker.I have used docker but there are other runtimes such as CRI-O\nKubeletPermalink Kubelet is an agent that runs on each worker node in the cluster. The agent is in charge of making sure that containers are running on the nodes as expected.\nMaster vs Worker nodesPermalink So now we know there are 2 types of nodes : Masternode and Worker node. How does a node become master or a worker node? A worker node has the containers are hosted and running .Hence to run these containers we need a Container Runtime such as docker installed in these machines.\nThe master has a kube API server and this is what differentiates the master from worker nodes. The worker node have the kubelet agent that interacts with the master to proivide health information about the worker nodes and carries out the instrcutions given by the master node on worker nodes.The master has all this information stored in key value store (etcd) known as the etcd.The master also has the controller and scheduler.\nKubectlPermalink kubectl is a commandline tool is used to deploy and manage applications in a cluster.Basically we are going to use these commands from the kubectl tool to get us information (kubectl get,status describe) about the nodes and other components in the cluster and to manage many other operations.\nkubectl run ‚ÄìUsed to deploy an application onto the cluster\nkubectl get cluster-info ‚ÄìUsed to fetch the cluster information\nkubectl get nodes ‚ÄìUsed to fetch information about nodes.\nThat is all on basic overview.Next article will be focused on pod and how pods work in nodes in kubernetes.\n","permalink":"https://codeklutz.com/posts/tackling-procrastination-and-kubernetes-study/","summary":"After a long series of procrastination and getting the hit of motivation from reading Atomic Habits(great book which I recommend others) ,I‚Äôm finally learning kubernetes basics.As a motivator to get better at writing and publish more posts as well as learn kubernetes.I have decided to publish 1 article every Sunday.I would like to post 2 posts per week but I want to start small and consistent. Once again I‚Äôm treating my blog as a journal to showcase how much I actually understand kubernetes.","title":"Tackling procrastination and kubernetes study"},{"content":"I tried a lot of things in January not necessarily everything learnt was used and and not every side project which I worked on got live.\nHowever I learnt many lessons from my own failures and gained more insights when I started some initiatives. So just a small gist of looking back on January and mid February.\nMy Blog! codeklutz.com I have been wanting to make my own tech blog for a while now but I needed something which didn‚Äôt necessary requires much code or db maintenance.I didn‚Äôt want to opt for WordPress for the same reason.\nJekyll with GitHub pages is a life saver here! Also learnt a lot on custom domains after buying my own domain,about Google analytic and SEO.Plus customising Jekyll site with themes has been fun.\nLetters to me This idea struck me in the wee hours at night.I always get some random tech ideas or where I am curious about something and think about it as to how I would do this particular task.\nI think of this site as an idea jar üí° or tech journal üìù where I jot down my wacky, scrambling thoughts.Something which I can look back on for ideas when I don‚Äôt feel creative or as starting thinking point for my small side projects.Some tech thoughts which aren‚Äôt polished enough for a blog but are useful tiny ideas which provide insight. Also since it‚Äôs on the internet maybe someone might find it useful or insightful? I‚Äôm thinking of adding an rss feed to this in the future if anyone would be interested in following this.\nExpiermenting with audio in blogs Based on the idea mentioned in letters.codeklutz.com decided to implement an audio feature for this blog.I tried finding some open source or free alternative.And I did find one but sadly this one proved to be a failure at the current moment.\nThe audio is decent but the voices which I found are too mechanical and monotonous to listen continuously.I shall still try finding some open source alternative because I don‚Äôt want to invest in paid alternatives for this small blog at the moment.\nNoteKlutz https://note.codeklutz.com This mini project is again a part of implementation of the idea mentioned in letters.codeklutz.com It already proving to be useful;) I realised I write more markdown (for creating study notes +writing this blog) so I felt the need to create my own editor which is suited for myself and at the same time not fear giving my data to someone or idk?(lmao)\nBut main focus was not to use another app just to create notes and since I use browser more than anything else this seemed like a good idea\nIt‚Äôs a small,minimal project which does exactly what I need it to do and does it right (at least for me biased hereü§´) It‚Äôs like my second organising brain üß†.The code is an absolute mess and needs heavy work which I will do my pushing small updates on weekendsü§≠.\nSo this was all for January and Mid Feb\n","permalink":"https://codeklutz.com/posts/tech-recap-journal-january/","summary":"I tried a lot of things in January not necessarily everything learnt was used and and not every side project which I worked on got live.\nHowever I learnt many lessons from my own failures and gained more insights when I started some initiatives. So just a small gist of looking back on January and mid February.\nMy Blog! codeklutz.com I have been wanting to make my own tech blog for a while now but I needed something which didn‚Äôt necessary requires much code or db maintenance.","title":"Tech Recap Journal- Januaryüìì"},{"content":"avigation, editing, development using terminal and zsh . But recently due to unforeseen updates, my bios was messed up big time which has led me unable to install Linux for the time being. But the work and learning never stops and nor shall I ! ‚ò∫ I don‚Äôt hate windows but it‚Äôs definitely not my first choice for development and coding after discovering Linux.ü§≠\nBut Thanks to WSL, windows terminal, and the beautiful zsh .I can get that Linux experience on windows!\nSo this is just a blog post on how I customized my terminal on windows 10 using wsl, windows terminal,zsh, and many more fun plugins which I use on my Linux as well as windows for development(work or home). What is wsl? It stands for windows subsystem for Linux and it\u0026rsquo;s a feature of Windows that allows developers to run Linux file systems,command-line tools etc directly on windows!(Goodbye painful windows mouse navigation) First, you need the wsl feature on windows 10 by going to Start -\u0026gt;Type windows feature on search and below checkbox should be checked for enabling windows subsystem for Linux. Now you need to install wsl which you can by going Start-\u0026gt; Microsoft store -\u0026gt;type ubuntu.Im installing Ubuntu wsl since I\u0026rsquo;m familiar with it you can also change distros. I\u0026rsquo;m also installing another app called windows terminal because it\u0026rsquo;s much better in terms of ui to me as compared to Ubuntu terminal.This is optional. At this point, it\u0026rsquo;s your choice whether you want to continue with the Ubuntu terminal or use the windows terminal.If you decide with the former,skip the next para and if you decide with the latter then you need to set windows terminal as your default shell. Now by default windows terminal opens the power shell, to set to Ubuntu Go to settings as shown below\nNow you have a Ubuntu shell that has bash. I personally use zsh with OhMyZsh for my work for that beautiful productivity. Using OhMyZsh features like navigating without using cd, usage of ll, easier tab-click based navigation, and much more!\nNote that zsh and OhMyZsh are different. When you install OhMyZsh, many plugins come with it for your rescue! So to install zsh. Update the libraries first then install zsh.\nsudo apt-get install update sudo apt install -y zsh Then Install ohmy zsh\nsh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; Now your previous~/.zshrc config will be replaced by ohmyzsh To customize the shell next install powerlevel10k.\ngit clone‚Ää-‚Äädepth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k This command clones the repo and now go to your ~/.zshrc and set the theme as power level 10k And then\nsource ~/¬†.zshrc Note: To reflect every change you make, do source ~/.zshrc in the terminal. And then this will give you a set of options to configure which you can decide for your customization.\nMy favourite plugins I use these plugins daily and they make my life super smooth !\nFzf It\u0026rsquo;s a fuzzy finder command-line tool that lets your fuzzy find anything (files directories git branches you name it )across file system. You can use ti write your custom fuzzy find scripts to find anything.I have posted a link if my current config and aliases for reference. Clone the repo from any directory and just run the install script.\ngit clone‚Ää-‚Äädepth 1 https://github.com/junegunn/fzf.git ~/.fzf ~/.fzf/install Here is a small example of small WIP config for reference.\nZsh Auto-suggestions This one Autocompletes while you type a command.This is useful especially when you type commands which you use daily but need to to try multiple times such as navigating and printing log at a specific long location. Git Clone the zsh-autocomplete plugin in the OhMyZsh plugin folder.\n$ sudo git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions Once that is done, add the plugin in the ~/.zshrc file\u0026rsquo;s plugin list.\nplugins=( ‚Ä¶ zsh-autosuggestions ) Zsh Syntax highlighting This one automatically highlights zsh commands as you type. This saves a lot of typing on my part. Git Clone the zsh-syntax-highlighting plugin in the OhMyZsh plugin folder.\n$ sudo git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting And once again add it to the plugins list of the .zshrc file.\nplugins=( ‚Ä¶ zsh-syntax-highlighting ) Note: To reflect every change you make, do source ~/.zshrc in the terminal.\nReadymade Github Aliases from Oh My Zsh Usually one defines short github aliases such as g.b forgit branch or g.c for git checkout in ~/.zshrc but you know by using ohMyZsh already has a list of easy git aliases configured. The format is first 2‚Äì3 letters of the first letter of the command such as\ngb git branch List of local branches gba git branch -a List of local and remote branches gcam git commit -am Add all files to stage and commit gcmsg git commit -m Git commit message gco git checkout Change branch gco‚Ää-‚Äägit checkout to the previous branch Change branch to the previous one gd git diff Files differences in staging gfa git fetch‚Ää-‚Ääall‚Ää-‚Ääprune Fetch all remote branches, delete branch if upstream is gone gl git pull Pull from remote gp git push Push to remote gpsup git push‚Ää-‚Ääset-upstream origin [currentbranch] Set upstream branch gst git status Local files to commit I use these git aliases daily and they make working super fun.I recommend going through oh-my-zsh git aliases cheatsheets\nThat\u0026rsquo;s all folks! This is my current setup in windows for development and this is still a work in progress that can keep changing but these plugins and zsh are something that has made the experience of using windows quite fun.\n","permalink":"https://codeklutz.com/posts/making-peace-with-windowsinstalling-wslzshpowerlevel10kfzf-many-more-fun-plugins-for-easy-development/","summary":"avigation, editing, development using terminal and zsh . But recently due to unforeseen updates, my bios was messed up big time which has led me unable to install Linux for the time being. But the work and learning never stops and nor shall I ! ‚ò∫ I don‚Äôt hate windows but it‚Äôs definitely not my first choice for development and coding after discovering Linux.ü§≠\nBut Thanks to WSL, windows terminal, and the beautiful zsh .","title":"Making Peace with Windows!Installing wsl,zsh,powerlevel10k,fzf \u0026 many more fun plugins for easy development"},{"content":"These days I am more into creating backend projects which include microservices.But if anyone wants to test these services one needs postman or do the old classic way of curl command.\nBoth do the job brilliantly but what if I wanted some user who doesn‚Äôt want to install postman or use curl and still wants to test my live APIs thru the browser? I came across this swagger open API specification and this is a really handy tool!\nIn layman‚Äôs terms, Swagger OpenAPI specification provides API documentation for REST APIs. An OpenAPI file allows you to describe all the APIs within the project and even lets you try out the APIs!\nAvailable endpoints can be /projectApi and all operations on each endpoint which can GET /getProjectApi , POST /insertProjectApi , DELETE /deleteProjectApi .\nAlso, integration of swagger open API is pretty painless in spring boot and it lets users try out the APIs within the browser without any installation of any software from the user (sounds pretty convenient and sweet to me)\nIn this post, I will describe how I integrated swagger open API in Spring boot project.First you need a spring boot project having basic dependcies using Spring Initializr https://start.spring.io/ or you could use this project used in the example here\nFirst add the springdoc-openapi-ui dependency to pom.xml:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springdoc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springdoc-openapi-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; Then run the application and check the below url to check open api specification\nhttp://localhost:8080/v3/api-docs/ You should be able to see something like this You can also add a custom path by adding entry in application.properties file\nspringdoc.api-docs.path=/api springdoc.swagger-ui.path=/swagger springdoc.swagger-ui.operationsSorter=method Check http://localhost:8080/swagger for web UI.To show you in this example we have a following apis in the controller\npackage com.TestDocker.BooksDocker.Controllers; import java.util.List; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpStatus; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.server.ResponseStatusException; import com.TestDocker.BooksDocker.Models.Book; import com.TestDocker.BooksDocker.Repository.BookRepository; @RestController public class MainController { @Autowired public BookRepository bookRepository; @GetMapping(\u0026#34;/test\u0026#34;) public String test() { return new String(\u0026#34;Working from DOcker Bopoks proj \u0026#34;); } @GetMapping(\u0026#34;/\u0026#34;) public List\u0026lt;Book\u0026gt; fetchAllBooks() { List\u0026lt;Book\u0026gt; books; try { books = bookRepository.findAll(); } catch (Exception ex) { throw new ResponseStatusException(HttpStatus.INTERNAL_SERVER_ERROR, \u0026#34;Error occured in fetchAllBooks\u0026#34;, ex); } return books; } @GetMapping(\u0026#34;/{bookID}\u0026#34;) public Book fetchBookfromID(@PathVariable(\u0026#34;bookID\u0026#34;) Long bookID) { Book book; try { book = bookRepository.getById(bookID); } catch (Exception ex) { throw new ResponseStatusException(HttpStatus.INTERNAL_SERVER_ERROR, \u0026#34;Error Occured in fetchBookfromID\u0026#34;, ex); } return book; } @GetMapping(\u0026#34;/search/{title}\u0026#34;) public List\u0026lt;Book\u0026gt; searchBookByTitle(@PathVariable(\u0026#34;title\u0026#34;) String title) { List\u0026lt;Book\u0026gt; books; try { //System.out.println(title); books = bookRepository.fuzzySearchByTitle(title); System.out.println(books); } catch (Exception ex) { throw new ResponseStatusException(HttpStatus.INTERNAL_SERVER_ERROR, \u0026#34;Error Occured in searchBookByTitle\u0026#34;, ex); } return books; } @PostMapping(\u0026#34;/insertBooks\u0026#34;) public String insertBooks(@RequestBody List\u0026lt;Book\u0026gt; books) { for (Book b : books) { System.out.println(b.toString()); Book b1 = bookRepository.save(b); if (b1 == null) return \u0026#34;Book object is null\u0026#34;; } return null; } } So the swagger ui look something like this. Also json docs will be available at http://localhost:8080/api springdoc.swagger-ui.operationsSorter=method sorts the API paths in order of their HTTP methods. You can try and test the apis from web ui too.It also shows schema information! Overall this is a much convenient way of setting up documentation for your apis which can be handy in some situations.\nThat‚Äôs all folks!\n","permalink":"https://codeklutz.com/posts/integrating-swagger-openapi-for-easy-api-documentation-in-spring-boot/","summary":"These days I am more into creating backend projects which include microservices.But if anyone wants to test these services one needs postman or do the old classic way of curl command.\nBoth do the job brilliantly but what if I wanted some user who doesn‚Äôt want to install postman or use curl and still wants to test my live APIs thru the browser? I came across this swagger open API specification and this is a really handy tool!","title":"Integrating Swagger OpenAPI for easy API documentation in spring boot"},{"content":"I was recently studying about using cron jobs in spring boot for a particular use case for my small side project. I ended up not using the cron job but rather went the SQL way(will explain this in detail below). However,in the process I learnt a lot about cron jobs and scheduling in spring boot so this is just a small article about my learnings.\nBut first I shall tell you a little about my use case and why I thought about cron jobs in the first place‚Ä¶..\nUse case My application was inserting data (let‚Äôs call it smash data for simplicity for now)in the database.Each smash data has a certain expiry period and after that expiry period, that data should no longer remain in the database.But the expiry period will be different for each smash data.\nExample:\nsmash 1, expiryperiod :10mins\nsmash 2 ,expiryperiod :60mins\nsmash 3 ,expiryperiod :150mins . . . etc.\nNow my first line of thinking ended up being cron jobs which led to me studying about cron jobs and scheduled in spring boot.To answer it simply I didn‚Äôt end up taking this route is because cron jobs or scheduled tasks are suited when we expect the task to execute at only a particular point of time or where we expect functionality to be executed at w particular time on an hourly/daily /weekly/monthly basis. I could get the cron job to delete the data but to delete WHICH data smash 1 or smash 2? That would mean I would have to check the DB. So the process would be something like:-\nFetch all rows from DB. Check timestamp of each row data against current timestamp and delete accordingly. I wanted to avoid writing the searching, comparing time logic (dates, in general, can be a pain sometimes).The logic which I did ended up going through was events in SQL since I‚Äôm using MySQL db for the use case\nMysql events are tasks that run according to a particular schedule ‚Ä¶hence they can be called as scheduled events\nWhen an event is created in MySQL, a named database object is created and this object consists of one or more SQL statements to be executed at some regular intervals.Using events,I didn‚Äôt have to retrieve and search the data (as I had to do in the spring boot controller ) . I could just write an event such as\nDelete from table1 where expiry period \u0026lt; NOW(); And schedule this to execute every minute. Which was would check for that expiryPeriod column in each row and compare with time NOW() So any rows whose expiryperiod has passed will be deleted from db.\nThe only thing to note I see in this approach, for now, is that this is database dependent so when I host this side project (a hopeful dream) I need to make sure events is configured for the same. So this was the use case now back to cron jobs!\nCron jobs or schedule tasks in spring boot.Permalink When a situation arises where we expect the task to execute at only a particular point of time or where we expect functionality to be executed at a particular time on an hourly/daily /weekly/monthly basis. Cron jobs are suitable for this use case. In spring this sort of scheduled task can be achieved through @Scheduled annotation.\nThere are a few rules while using the @Scheduled annotation: 1. The method should typically have a void return type else the returned value will be ignored.\nthe method should not expect any parameters. First, to enable scheduling in the spring boot project, use @EnableScheduling in the main class.\npublic class Application { public static void main(String[] args) { SpringApplication.run(PasteBinApplication.class, args); } } Scheduling using CRON expressions @Component public class SchedulerService { @Scheduled(cron=\u0026#34;*/15 * * * * ?\u0026#34;) public void testScheduled() { System.out.println(\u0026#34;Method executed at every 15 seconds. Current time is :: \u0026#34;+ new Date()); } } A guide for cron jobs: cron Image source :Java Techonline SEC MIN HOURS DAY MONTH WEEKDAY * * * * * * Scheduling using initial delay,Fixed Delay or Fixed Rate The main difference between Fixed Delay and Fixed Rate is : Fixed Delay : controls the next execution time when the last execution finishes. Fixed Rate : makes Spring run the task on periodic intervals even if the last invocation may be still running.\nFixed Delay\n@Component public class SchedulerService { @Scheduled(fixedDelay = 1000, initialDelay = 5000) public void testScheduled() { System.out.println(\u0026#34;Method executed with fixed delay and initial delay . Current time is :: \u0026#34;+ new Date()); } } Also Fixed Delay can take input in String and Integer. @Scheduled(fixedDelayString = ‚Äú7000‚Äù) @Scheduled(fixedDelayString = 7000) Fixed Rate:\n@Component public class SchedulerService { @Scheduled(fixedRate = 1000) public void testScheduled() { System.out.println(\u0026#34;Method executed with fixed rate . Current time is :: \u0026#34;+ new Date()); } } That‚Äôs all folks.Learning about events and cron jobs and where could be applied was interesting to learn when applied on some small practical application.\n","permalink":"https://codeklutz.com/posts/which-would-you-go-for-spring-boot-cron-jobscheduled-tasks-vs-events-in-mysql/","summary":"I was recently studying about using cron jobs in spring boot for a particular use case for my small side project. I ended up not using the cron job but rather went the SQL way(will explain this in detail below). However,in the process I learnt a lot about cron jobs and scheduling in spring boot so this is just a small article about my learnings.\nBut first I shall tell you a little about my use case and why I thought about cron jobs in the first place‚Ä¶.","title":"Which would you go for? Spring boot cron job,scheduled tasks vs Events in Mysql."},{"content":"I deployed my portfolio site and wanted to try out github actions and this is my experience of automating the deployment. This article is more focused on how you can use the GitHub actions and how easy it is to deploy your code to GitHub pages rather than the portfolio site code.So every time you make an update or build to your website ,the changes are automatically reflected and this automated deploying process makes work much faster.\nThe way GitHub action works is you create actions in your repositories by creating one or more yaml files and these are called workflows.Workflows now can handle build tasks like CI CD. This means you use the action to test your code and push the site to the desired hosting platform (in this case GitHub pages ) when the main branch changes . First step assuming that you have a GitHub account is to create a repository having your website code in it.Now I have a bootstrap website but in the future I do plan on adding node JS so I already added package.json.\n{% gist 7fc9e560ec958d6fb9876019e298e02f %}\n{ \u0026#34;name\u0026#34;: \u0026#34;shwetarkadam.github.io\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Portfolio\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.html\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;npm run clean \u0026amp;\u0026amp; npm run imagemin \u0026amp;\u0026amp; npm run copyfonts \u0026amp;\u0026amp; npm run copydata \u0026amp;\u0026amp; npm run usemin\u0026#34;, \u0026#34;clean\u0026#34;: \u0026#34;rimraf dist\u0026#34;, \u0026#34;copyfonts\u0026#34;: \u0026#34;copyfiles -f node_modules/font-awesome/fonts/* dist/fonts\u0026#34;, \u0026#34;copydata\u0026#34;: \u0026#34;copyfiles -f src/js/* dist/js\u0026#34;, \u0026#34;imagemin\u0026#34;: \u0026#34;imagemin src/img/* -o dist/img\u0026#34;, \u0026#34;lite\u0026#34;: \u0026#34;lite-server\u0026#34;, \u0026#34;start\u0026#34;: \u0026#34;npm run lite\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34;, \u0026#34;usemin\u0026#34;: \u0026#34;usemin index.html -d dist --htmlmin -o dist/index.html\u0026#34; }, \u0026#34;repository\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;git@github.com:shwetarkadam/portfolio.git\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;Shweta Kadam\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;MIT\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;bootstrap\u0026#34;: \u0026#34;^4.4.1\u0026#34;, \u0026#34;font-awesome\u0026#34;: \u0026#34;^4.7.0\u0026#34;, \u0026#34;jquery\u0026#34;: \u0026#34;^3.5.1\u0026#34;, \u0026#34;popper.js\u0026#34;: \u0026#34;^1.16.0\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;copyfiles\u0026#34;: \u0026#34;^2.2.0\u0026#34;, \u0026#34;imagemin-cli\u0026#34;: \u0026#34;^5.1.0\u0026#34;, \u0026#34;lite-server\u0026#34;: \u0026#34;^2.5.4\u0026#34;, \u0026#34;rimraf\u0026#34;: \u0026#34;^3.0.2\u0026#34;, \u0026#34;usemin-cli\u0026#34;: \u0026#34;^0.6.0\u0026#34; } } Verify all your changes as correct by first in your root folder running the command:\nnpm install npm install\nand after installing node modules run the command:\nrun npm start so you should get your output in localhost something like this\nNow that you have ensured that the project runs properly in your local machine,it is ready to be deployed to GitHub pages. You will only need to commit and push your changes to the main branch of a repo and ensure that the settings are pointing to the correct branch to display a site for that. Now the file that does this is that deploy.yml file which we will use to create the workflow.\nname: Build and Deploy on: push: branches: - main jobs: build-and-deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 with: persist-credentials: false - name: Install and 06Build run: | npm install npm run build - name: Deploy uses: JamesIves/github-pages-deploy-action@releases/v3 with: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} BRANCH: gh-pages FOLDER: dist Now this yaml file which can be found .github/workflows/deploy.yml file in local ,you can rename the file whatever you like.It tells the github actions to install the project dependencies run a build script and put that required files in a output folder name dist and upload the contents of the dist folder to the gh-pages branch and if the branch does not exist it will create that branch.The workflow to deploy the site to github-pages you can find that from James Ives GitHub pages deploy action. If you have any existing site or code and you want to publish it to get pages you only need this file to be added into your project. You could go to your github repo Actions Tab -\u0026gt; Create Simple Workflow and copy paste the above content in your yaml file.\nOnce you have a site ready for GitHub Pages, and your project includes the .github/workflows/deploy.yml file, you only need to commit and push your changes to the main branch of your repository. You can the ongoing workflow by going to Actions=\u0026gt;build and deploy.Also this is the place where you can debug what went wrong in case your workflow fails.\nAfter the GitHub Actions have run, ensure settings are pointing to the correct branch to display your site. Go to the settings of your repository and ensure that the source for GitHub Pages is using the correct branch. It is close to the bottom of the main settings page.\nIt does take some time at the start to load in the browser but once available you can click on the link in the green bar above. Now every time you make a push to the main branch ,the changes are reflected in the main site.\nMy Portfolio Site: Click Here\nThat‚Äôs all folks. Happy Learning.\n","permalink":"https://codeklutz.com/posts/deploying-my-portfolio-website-for-free-on-github-pages-using-github-actions/","summary":"I deployed my portfolio site and wanted to try out github actions and this is my experience of automating the deployment. This article is more focused on how you can use the GitHub actions and how easy it is to deploy your code to GitHub pages rather than the portfolio site code.So every time you make an update or build to your website ,the changes are automatically reflected and this automated deploying process makes work much faster.","title":"Deploying my portfolio website for free on Github Pages using GitHub actions"},{"content":"Just revisiting and explaining myself Polymorphism concept here through a blog post. The words Polymorphism means multiple forms.\nIn Java ,Polymorphism means multiple forms of an object. We shall divide this article into 3 sections.\n1.Syntax\n2.Calling a variable polymorphically.\n3.Calling a method polymorphically.\n1.SyntaxPermalink Now in polymorphism in Java, the thumb key rule to remember is\nsuper = subPermalink Meaning the variable reference (LHS) must always be a super class reference and the object initialization(RHS) must a sub class.\nFor Example: class A{\n} class B extends A{ } class C extends B{ } class D extends A{ }\nSo valid and invalid syntax according to the thumb rule will be\nA a =new B(); //VALID B b=new D(); //NOT VALID C c=new A(); //VALID A a1=new D(); //VALID 2.Calling a variable polymorphically.Permalink If a variable is called from a polymorphic object,we follow the reference i.e. the super class. And if the variable is not present in the super class ,it results in a COMPILE ERROR. EG:\nclass A{ int x=5; } class B extends A{ int x=10; } class App{ public static void main(String[]args){ A a=new B(); System.out.println(a.x); //What do u think is the output class A x value (5)or class B x value(10)?Follow the rule. } } OUTPUT: 5 Calling a method polymorphically.Permalink If a method is called from a polymorphic object ,we follow a 2 step procedure: 1.We got to the super class and check whther the method is present or not.\nif(present) Goto to step 2 else COMPILE ERROR 2.Come to the sub class and check wther the method is overrided or not.\nif(overrided) Call the sub-class version else Call the super -class version. Eg:\nclass A{ void m1(){ System.out.println(\u0026#34;A\u0026#34;); }} class B extends A{ void m1(){ System.out.println(\u0026#34;B\u0026#34;); }} class App{ public static void main(String[]args){ A a=new B(); a.m1(); //Follow the rule B=new B(); b.m1(); //Normal sub class object method call }} OUTPUT: B B So that‚Äôs all for polymorphism in java.\nHappy Learning :)\n","permalink":"https://codeklutz.com/posts/polymorphism-in-java/","summary":"Just revisiting and explaining myself Polymorphism concept here through a blog post. The words Polymorphism means multiple forms.\nIn Java ,Polymorphism means multiple forms of an object. We shall divide this article into 3 sections.\n1.Syntax\n2.Calling a variable polymorphically.\n3.Calling a method polymorphically.\n1.SyntaxPermalink Now in polymorphism in Java, the thumb key rule to remember is\nsuper = subPermalink Meaning the variable reference (LHS) must always be a super class reference and the object initialization(RHS) must a sub class.","title":"Polymorphism in Java"},{"content":"Constructors are used every time to initialize instance variables. There are some additional rules associated with constructors that are often asked in interviews.Hence revising those here through a blog post.\nA constructor is used to initialize instance variables When an object of an class is created,JVM goes to the class and searches for that matching constructor.If Constructor is NOT PRESENT it gives a compile error. By default every class has a constructor called default no argument constructor. class A{ A(){ //default no arg constructor }} A programmer can have multiple constructors in a class provided their signatures are different this is called constructor overloading. class A{ A(){ //some code } A(int x){ //some code } A(float x){ //some code } A(float x,int y){ //some code } A(int x,float y){ } A(int z){}//THIS WILL GIVE COMPILE ERROR SInce its already defined on top. } A a=new A(); new A();//goes to first matching constructor JVM always calls the matching constructor from the class.HOWEVER,a programmer can call other constructors of this class by using the the this() method. class A{ A(){ System.out.println(\u0026#34;A\u0026#34;); //I A(int x){ this(); //this will go to constructor A(); System.out.println(\u0026#34;AA\u0026#34;); //II } } class App{ public static void main(String[]args){ new A(5); }} OUTPUT: A AA If a programmer desires it can call the constructor of the super class as well from its own constructor using the super() method. class A{ A(){ System.out.println(\u0026#34;A\u0026#34;); //I } } class B extends A{ B(){ super(); //this is called implicitly refer next point also System.out.println(\u0026#34;B\u0026#34;); }} class HelloWorld { public static void main(String[] args) { new B(); } } OUTPUT: A B Whenever a programmer creates a constructor ,JVM writes super() in every constructor implicitly as its first line. Note:If a class does not extend any class it by default extends the Object class. Do Try this code in your ide to see it for yourself\nclass A{ A(){ //super will be called implicitly at the first line of this constructor and here since it does not extend any class it will extend the Object class System.out.println(\u0026#34;A\u0026#34;); //I } A(int x){ //super will be called implicitly at the first line of this constructor System.out.println(\u0026#34;AA\u0026#34;); }} class HelloWorld { public static void main(String[] args) { new A(5); } } OUTPUT: A AA That‚Äôs all for constructors in Java.\nHappy Learning :)\n","permalink":"https://codeklutz.com/posts/how-constructors-work-in-java/","summary":"Constructors are used every time to initialize instance variables. There are some additional rules associated with constructors that are often asked in interviews.Hence revising those here through a blog post.\nA constructor is used to initialize instance variables When an object of an class is created,JVM goes to the class and searches for that matching constructor.If Constructor is NOT PRESENT it gives a compile error. By default every class has a constructor called default no argument constructor.","title":"How constructors work in Java"}]